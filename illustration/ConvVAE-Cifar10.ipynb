{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "numSeed = 42\n",
    "np.random.seed(numSeed)\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, Conv2DTranspose, Activation, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from util import plotScatterDecode, plotProgress, plotCompDecode, plotScatterEncode, addNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100\n",
    "sizeBatch = 32\n",
    "sizeKernel = 3\n",
    "dimInter = 128\n",
    "dimEncode = 32\n",
    "layer_filters = [8, 16, 32, 64]\n",
    "stdEps = 1.0 \n",
    "ratRecon = 0.998\n",
    "factNoise = 0\n",
    "nameOptim = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(xTrain, _), (xTest, yTest) = cifar10.load_data()\n",
    "yTest = np.squeeze(yTest, axis=1)\n",
    "sizeDigit = xTrain.shape[1]\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "dimInput = xTrain.shape[1:]\n",
    "\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "xTrain\n",
    "\n",
    "xTrain = np.reshape(xTrain, [-1, *dimInput])\n",
    "xTest = np.reshape(xTest, [-1, *dimInput])\n",
    "xTrainNoise = addNoise(xTrain, factNoise=factNoise)\n",
    "xTestNoise = addNoise(xTest, factNoise=factNoise)\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 8)    224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 16)     1168        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 32)     4640        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 2, 2, 64)     18496       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 65,680\n",
      "Trainable params: 65,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 16, 16, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 8)         1160      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 3)         219       \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 98,643\n",
      "Trainable params: 98,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(dimInput))  # adapt this if using `channels_first` image data format\n",
    "x = inputs\n",
    "# Stack of Conv2D blocks\n",
    "# Notes:\n",
    "# 1) Use Batch Normalization before ReLU on deep networks\n",
    "# 2) Use MaxPooling2D as alternative to strides>1\n",
    "# - faster but not as good as strides>1\n",
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=sizeKernel,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "\n",
    "# Shape info needed to build Decoder Model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# Generate the latent vector\n",
    "x = Flatten()(x)\n",
    "x = Dense(dimInter, activation='relu')(x)\n",
    "zMean = Dense(dimEncode)(x)\n",
    "zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "def sampling(args):\n",
    "    zMean, zSigmaLog = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(zMean)[0], dimEncode),\n",
    "                              mean=0., stddev=stdEps)\n",
    "    return zMean + K.exp(zSigmaLog) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "# z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "z = Lambda(sampling)([zMean, zSigmaLog])\n",
    "encoder = Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "# Build the Decoder Model\n",
    "inputLatent = Input(shape=(dimEncode,), name='decoder_input')\n",
    "x = Dense(dimInter, activation='relu')(inputLatent)\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(x)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# Stack of Transposed Conv2D blocks\n",
    "# Notes:\n",
    "# 1) Use Batch Normalization before ReLU on deep networks\n",
    "# 2) Use UpSampling2D as alternative to strides>1\n",
    "# - faster but not as good as strides>1\n",
    "for filters in layer_filters[::-1]:\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=sizeKernel,\n",
    "                        strides=2,\n",
    "                        activation='relu',\n",
    "                        padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=3,\n",
    "                    kernel_size=sizeKernel,\n",
    "                    padding='same')(x)\n",
    "\n",
    "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "\n",
    "# Instantiate Decoder Model\n",
    "decoder = Model(inputLatent, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 32)                65680     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 32, 32, 3)         98643     \n",
      "=================================================================\n",
      "Total params: 164,323\n",
      "Trainable params: 164,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder = Encoder + Decoder\n",
    "# Instantiate Autoencoder Model\n",
    "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 30s 601us/step - loss: 0.6464 - val_loss: 0.6366\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 28s 551us/step - loss: 0.6345 - val_loss: 0.6340\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 27s 533us/step - loss: 0.6323 - val_loss: 0.6319\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 26s 530us/step - loss: 0.6309 - val_loss: 0.6313\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 27s 538us/step - loss: 0.6296 - val_loss: 0.6296\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 27s 538us/step - loss: 0.6287 - val_loss: 0.6294\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 0.6282 - val_loss: 0.6283\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 27s 532us/step - loss: 0.6274 - val_loss: 0.6279\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 0.6268 - val_loss: 0.6273\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 27s 533us/step - loss: 0.6264 - val_loss: 0.6270\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 27s 547us/step - loss: 0.6263 - val_loss: 0.6268\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 0.6261 - val_loss: 0.6267\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 27s 535us/step - loss: 0.6258 - val_loss: 0.6271\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 27s 541us/step - loss: 0.6257 - val_loss: 0.6264\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 27s 541us/step - loss: 0.6255 - val_loss: 0.6263\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 26s 526us/step - loss: 0.6253 - val_loss: 0.6267\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 0.6252 - val_loss: 0.6259\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 0.6251 - val_loss: 0.6265\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.6250 - val_loss: 0.6267\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 0.6249 - val_loss: 0.6258\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 0.6248 - val_loss: 0.6258\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 0.6248 - val_loss: 0.6257\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 0.6247 - val_loss: 0.6257\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 0.6246 - val_loss: 0.6262\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 0.6245 - val_loss: 0.6254\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 0.6245 - val_loss: 0.6256\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 0.6244 - val_loss: 0.6251\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 0.6244 - val_loss: 0.6253\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 25s 504us/step - loss: 0.6244 - val_loss: 0.6252\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 0.6243 - val_loss: 0.6256\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.6243 - val_loss: 0.6252\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.6243 - val_loss: 0.6256\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.6242 - val_loss: 0.6255\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 0.6242 - val_loss: 0.6253\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 0.6242 - val_loss: 0.6252\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 0.6242 - val_loss: 0.6250\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 25s 509us/step - loss: 0.6242 - val_loss: 0.6254\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.6241 - val_loss: 0.6250\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 0.6242 - val_loss: 0.6252\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.6241 - val_loss: 0.6254\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 25s 510us/step - loss: 0.6241 - val_loss: 0.6254\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 26s 512us/step - loss: 0.6241 - val_loss: 0.6252\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.6241 - val_loss: 0.6249\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 26s 511us/step - loss: 0.6241 - val_loss: 0.6254\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 26s 512us/step - loss: 0.6240 - val_loss: 0.6250\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 26s 511us/step - loss: 0.6240 - val_loss: 0.6255\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 26s 510us/step - loss: 0.6240 - val_loss: 0.6249\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 26s 512us/step - loss: 0.6240 - val_loss: 0.6254\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.6240 - val_loss: 0.6252\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 0.6240 - val_loss: 0.6254\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 24s 483us/step - loss: 0.6239 - val_loss: 0.6251\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 0.6240 - val_loss: 0.6252\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.6239 - val_loss: 0.6250\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 0.6239 - val_loss: 0.6249\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.6239 - val_loss: 0.6248\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 0.6238 - val_loss: 0.6254\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.6239 - val_loss: 0.6250\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 0.6238 - val_loss: 0.6250\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.6238 - val_loss: 0.6251\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.6238 - val_loss: 0.6251\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.6238 - val_loss: 0.6248\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.6238 - val_loss: 0.6249\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.6238 - val_loss: 0.6247\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.6238 - val_loss: 0.6250\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.6238 - val_loss: 0.6252\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 0.6238 - val_loss: 0.6250\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 0.6237 - val_loss: 0.6248\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 0.6238 - val_loss: 0.6254\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.6237 - val_loss: 0.6249\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.6237 - val_loss: 0.6255\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 0.6237 - val_loss: 0.6250\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.6237 - val_loss: 0.6249\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.6237 - val_loss: 0.6250\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.6237 - val_loss: 0.6249\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.6237 - val_loss: 0.6247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.6236 - val_loss: 0.6250\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.6237 - val_loss: 0.6249\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.6236 - val_loss: 0.6248\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 0.6237 - val_loss: 0.6250\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.6237 - val_loss: 0.6247\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.6236 - val_loss: 0.6251\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.6237 - val_loss: 0.6249\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.6236 - val_loss: 0.6249\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 0.6236 - val_loss: 0.6248\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.6236 - val_loss: 0.6247\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 25s 498us/step - loss: 0.6236 - val_loss: 0.6249\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.6236 - val_loss: 0.6248\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.6236 - val_loss: 0.6246\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 25s 500us/step - loss: 0.6236 - val_loss: 0.6248\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 0.6236 - val_loss: 0.6252\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 25s 500us/step - loss: 0.6236 - val_loss: 0.6248\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.6236 - val_loss: 0.6250\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 0.6235 - val_loss: 0.6248\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 25s 501us/step - loss: 0.6236 - val_loss: 0.6247\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 25s 508us/step - loss: 0.6236 - val_loss: 0.6248\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 25s 502us/step - loss: 0.6235 - val_loss: 0.6251\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 25s 502us/step - loss: 0.6236 - val_loss: 0.6249\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 25s 508us/step - loss: 0.6236 - val_loss: 0.6249\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 25s 501us/step - loss: 0.6235 - val_loss: 0.6250\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 25s 501us/step - loss: 0.6235 - val_loss: 0.6248\n"
     ]
    }
   ],
   "source": [
    "def lossVAE(zMean, zSigmaLog):\n",
    "    def loss(tensorInput, tensorDecode):\n",
    "        lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "        lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "#         lossKL = - 0.5 * K.mean(1 + zSigmaLog - K.square(zMean) - K.exp(zSigmaLog), axis=-1)\n",
    "        return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "    return loss\n",
    "\n",
    "autoencoder.compile(optimizer=nameOptim, loss=lossVAE(zMean, zSigmaLog))\n",
    "\n",
    "# Train the autoencoder\n",
    "tic = time()\n",
    "history = autoencoder.fit(xTrainNoise, xTrain,\n",
    "                epochs=numEpochs,\n",
    "                batch_size=sizeBatch,\n",
    "                shuffle=True,\n",
    "                validation_data=(xTest, xTest))\n",
    "timeTrain = time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the historical training progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"traing consumed: \" + str(timeTrain) + \" seconds\")\n",
    "plotProgress(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the encoding and decoding results of testing data, and get the mean/std of the encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encodeTest = encoder.predict(xTestNoise)\n",
    "decodeTest = decoder.predict(encodeTest)\n",
    "meanEncTest = np.mean(encodeTest, axis=0)\n",
    "stdEncTest = np.std(encodeTest, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare original digitals with the decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plotCompDecode() got an unexpected keyword argument 'sizeReshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a29d0aef2bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotCompDecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecodeTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizeReshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: plotCompDecode() got an unexpected keyword argument 'sizeReshape'"
     ]
    }
   ],
   "source": [
    "plotCompDecode(xTest, decodeTest, sizeReshape = (32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the scatter of the encoding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "\n",
    "plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "scoreSilh = silhouette_score(encodeTest, yTest)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the decoding results from the encoding scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "plotScatterDecode(decoder, (32,32,3), xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timeTrain, history.history[\"loss\"][numEpochs-1], history.history[\"val_loss\"][numEpochs-1], scoreSilh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, _), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 32, 32, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[-1, *dimInput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
