{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "numSeed = 42\n",
    "np.random.seed(numSeed)\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, Conv2DTranspose, Activation, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import plotScatterDecode, plotProgress, plotCompDecode, plotScatterEncode, addNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 50\n",
    "sizeBatch = 32\n",
    "sizeKernel = 3\n",
    "dimInter = 64\n",
    "dimEncode = 2\n",
    "layer_filters = [16, 32]\n",
    "stdEps = 1.0 \n",
    "ratRecon = 0.998\n",
    "factNoise = 0\n",
    "nameOptim = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(xTrain, _), (xTest, yTest) = mnist.load_data()\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "dimInput = [*xTrain.shape[1:], 1]  # adapt 28*28 as 28*28*1\n",
    "\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "xTrain\n",
    "\n",
    "xTrain = np.reshape(xTrain, [-1, *dimInput])\n",
    "xTest = np.reshape(xTest, [-1, *dimInput])\n",
    "xTrainNoise = addNoise(xTrain, factNoise=factNoise)\n",
    "xTestNoise = addNoise(xTest, factNoise=factNoise)\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 16)   160         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 32)     4640        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1568)         0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           100416      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            130         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            130         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 105,476\n",
      "Trainable params: 105,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1568)              101920    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 14, 14, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 106,881\n",
      "Trainable params: 106,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(dimInput))  # adapt this if using `channels_first` image data format\n",
    "x = inputs\n",
    "# Stack of Conv2D blocks\n",
    "# Notes:\n",
    "# 1) Use Batch Normalization before ReLU on deep networks\n",
    "# 2) Use MaxPooling2D as alternative to strides>1\n",
    "# - faster but not as good as strides>1\n",
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=sizeKernel,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "\n",
    "# Shape info needed to build Decoder Model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# Generate the latent vector\n",
    "x = Flatten()(x)\n",
    "x = Dense(dimInter, activation='relu')(x)\n",
    "zMean = Dense(dimEncode)(x)\n",
    "zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "def sampling(args):\n",
    "    zMean, zSigmaLog = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(zMean)[0], dimEncode),\n",
    "                              mean=0., stddev=stdEps)\n",
    "    return zMean + K.exp(zSigmaLog) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "# z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "z = Lambda(sampling)([zMean, zSigmaLog])\n",
    "encoder = Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "# Build the Decoder Model\n",
    "inputLatent = Input(shape=(dimEncode,), name='decoder_input')\n",
    "x = Dense(dimInter, activation='relu')(inputLatent)\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(x)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# Stack of Transposed Conv2D blocks\n",
    "# Notes:\n",
    "# 1) Use Batch Normalization before ReLU on deep networks\n",
    "# 2) Use UpSampling2D as alternative to strides>1\n",
    "# - faster but not as good as strides>1\n",
    "for numFilt in layer_filters[-2::-1]:\n",
    "    x = Conv2DTranspose(filters=numFilt,\n",
    "                        kernel_size=sizeKernel,\n",
    "                        strides=2,\n",
    "                        activation='relu',\n",
    "                        padding='same')(x)\n",
    "\n",
    "# Build the Conv2DTranspose layer for the pixel dimension\n",
    "x = Conv2DTranspose(filters=dimInput[-1],\n",
    "                    kernel_size=sizeKernel,\n",
    "                    strides=2,\n",
    "                    activation='relu',\n",
    "                    padding='same')(x)\n",
    "\n",
    "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "\n",
    "# Instantiate Decoder Model\n",
    "decoder = Model(inputLatent, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 105476    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         106881    \n",
      "=================================================================\n",
      "Total params: 212,357\n",
      "Trainable params: 212,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder = Encoder + Decoder\n",
    "# Instantiate Autoencoder Model\n",
    "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"decoder_target_1:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"decoder_1/decoder_output/Sigmoid:0\", shape=(?, ?, ?, 1), dtype=float32)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.6918 - val_loss: 0.6917\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.6918 - val_loss: 0.6917\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6918 - val_loss: 0.6917\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6917 - val_loss: 0.6917\n",
      "Epoch 15/50\n",
      "13696/60000 [=====>........................] - ETA: 8s - loss: 0.6917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-727fb85a7ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msizeBatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 validation_data=(xTest, xTest))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mtimeTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4171\u001b[0;31m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2957\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lossVAE(zMean, zSigmaLog):\n",
    "    def loss(tensorInput, tensorDecode):\n",
    "        print(tensorInput)\n",
    "        print(tensorDecode)\n",
    "        lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "        lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "#         lossKL = - 0.5 * K.mean(1 + zSigmaLog - K.square(zMean) - K.exp(zSigmaLog), axis=-1)\n",
    "        return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "    return loss\n",
    "\n",
    "autoencoder.compile(optimizer=nameOptim, loss=lossVAE(zMean, zSigmaLog))\n",
    "\n",
    "# Train the autoencoder\n",
    "tic = time()\n",
    "history = autoencoder.fit(xTrainNoise, xTrain,\n",
    "                epochs=numEpochs,\n",
    "                batch_size=sizeBatch,\n",
    "                shuffle=True,\n",
    "                validation_data=(xTest, xTest))\n",
    "timeTrain = time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the historical training progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXd///XJ8lkX0nClrDjAgKCIopacReqVWvrWu3mfWO3++5mq3axv9r6q3fbu7X2buvS2tZarSvWurSoVVxBAZEdgbAkBEjIvq/X94/rAEMIJEAmE5L38+E8ZubMmTOfE0Pec13XOdcx5xwiIiIHExPtAkREpO9TWIiISJcUFiIi0iWFhYiIdElhISIiXVJYiIhIlxQWIj3AzP5kZj/u5rqbzez8I92OSG9SWIiISJcUFiIi0iWFhQwYQffPt8xsuZnVmdkfzGyImb1oZjVm9rKZZYWtf6mZrTKzSjN7zcwmhL02zcyWBu97DEjs8FmXmNmy4L1vm9mUw6z5P81sg5mVm9mzZjY8WG5m9kszKzGzqmCfJgWvfdTMVge1bTOzmw/rByYSRmEhA80ngAuAY4GPAS8C3wFy8P8e/hvAzI4FHgW+BuQCLwD/MLN4M4sHngH+AgwCngi2S/Dek4AHgZuAbOA+4FkzSziUQs3sXOAnwFXAMGAL8Lfg5QuBs4L9yASuBsqC1/4A3OScSwMmAf8+lM8V6YzCQgaaXzvndjrntgFvAIucc+8755qAecC0YL2rgeedcy8551qAnwNJwOnAaUAIuNs51+KcexJ4L+wz/hO4zzm3yDnX5pz7M9AUvO9QfAp40Dm3NKjvNmCmmY0GWoA04HjAnHNrnHPbg/e1ABPNLN05V+GcW3qInyuyH4WFDDQ7wx43dPI8NXg8HP9NHgDnXDtQCOQFr21z+87CuSXs8Sjgm0EXVKWZVQIjgvcdio411OJbD3nOuX8D/wf8BthpZvebWXqw6ieAjwJbzGyBmc08xM8V2Y/CQqRzxfg/+oAfI8D/wd8GbAfygmW7jQx7XAjc6ZzLDLslO+cePcIaUvDdWtsAnHP3OOdOBk7Ad0d9K1j+nnPuMmAwvrvs8UP8XJH9KCxEOvc4cLGZnWdmIeCb+K6kt4F3gFbgv80szsyuAGaEvfcB4AtmdmowEJ1iZhebWdoh1vAI8DkzmxqMd/z/+G6zzWZ2SrD9EFAHNAJtwZjKp8wsI+g+qwbajuDnIAIoLEQ65ZxbB1wP/BrYhR8M/5hzrtk51wxcAXwWqMCPbzwd9t7F+HGL/wte3xCse6g1vAJ8H3gK35oZB1wTvJyOD6UKfFdVGX5cBeAGYLOZVQNfCPZD5IiYLn4kIiJdUctCRES6pLAQEZEuKSxERKRLCgsREelSXLQL6Ck5OTlu9OjR0S5DROSosmTJkl3Oudyu1us3YTF69GgWL14c7TJERI4qZral67XUDSUiIt2gsBARkS4pLEREpEv9ZsxCRORwtLS0UFRURGNjY7RLiajExETy8/MJhUKH9X6FhYgMaEVFRaSlpTF69Gj2nUi4/3DOUVZWRlFREWPGjDmsbagbSkQGtMbGRrKzs/ttUACYGdnZ2UfUelJYiMiA15+DYrcj3ccBHxY1jS388qUPWVZYGe1SRET6rAEfFm3tjl+9sp4lWyqiXYqIDECVlZX89re/PeT3ffSjH6Wysve+5A74sEhL9EcGVDW0RLkSERmIDhQWbW0Hv8DhCy+8QGZmZqTK2s+APxoqNsZIS4yjWmEhIlFw6623snHjRqZOnUooFCI1NZVhw4axbNkyVq9ezeWXX05hYSGNjY189atfZe7cucDeKY5qa2uZM2cOZ555Jm+//TZ5eXn8/e9/JykpqUfrHPBhAZCRFFLLQkT44T9Wsbq4uke3OXF4Oj/42AkHfP2uu+5i5cqVLFu2jNdee42LL76YlStX7jnE9cEHH2TQoEE0NDRwyimn8IlPfILs7Ox9trF+/XoeffRRHnjgAa666iqeeuoprr++Z6+mq7BAYSEifceMGTP2ORfinnvuYd68eQAUFhayfv36/cJizJgxTJ06FYCTTz6ZzZs393hdCgsUFiLiHawF0FtSUlL2PH7ttdd4+eWXeeedd0hOTubss8/u9FyJhISEPY9jY2NpaGjo8boG/AA3KCxEJHrS0tKoqanp9LWqqiqysrJITk5m7dq1LFy4sJer20stCxQWIhI92dnZnHHGGUyaNImkpCSGDBmy57XZs2dz7733MmXKFI477jhOO+20qNWpsEBhISLR9cgjj3S6PCEhgRdffLHT13aPS+Tk5LBy5co9y2+++eYerw/UDQVAelKI5tZ2GlsOflyziMhApbDAtyxAJ+aJiByIwoK9YaET80REOqewQC0LEZGuKCxQWIiIdEVhgcJCRKQrCgsUFiISPYc7RTnA3XffTX19fQ9X1DmFBf7QWVBYiEjvO1rCQiflEUxTnhCnsBCRXhc+RfkFF1zA4MGDefzxx2lqauLjH/84P/zhD6mrq+Oqq66iqKiItrY2vv/977Nz506Ki4s555xzyMnJ4dVXX41onQqLQLrO4haRF2+FHSt6dptDJ8Ocuw74cvgU5fPnz+fJJ5/k3XffxTnHpZdeyuuvv05paSnDhw/n+eefB/ycURkZGfziF7/g1VdfJScnp2dr7oS6oQIZSSGdZyEiUTV//nzmz5/PtGnTOOmkk1i7di3r169n8uTJvPzyy9xyyy288cYbZGRk9HptalkEND+UiBysBdAbnHPcdttt3HTTTfu9tmTJEl544QVuu+02LrzwQm6//fZerU0ti4DCQkSiIXyK8osuuogHH3yQ2tpaALZt20ZJSQnFxcUkJydz/fXXc/PNN7N06dL93htpalkE0pM0wC0ivS98ivI5c+Zw3XXXMXPmTABSU1N5+OGH2bBhA9/61reIiYkhFArxu9/9DoC5c+cyZ84chg0bFvEBbnPORW7jZrOBXwGxwO+dc3d1eP0bwH8ArUAp8Hnn3BYzmwr8DkgH2oA7nXOPHeyzpk+f7hYvXnzYtd75/Gr+snALa38057C3ISJHnzVr1jBhwoRol9ErOttXM1vinJve1Xsj1g1lZrHAb4A5wETgWjOb2GG194HpzrkpwJPAT4Pl9cCnnXMnALOBu80sM1K1gu+Gamxpp6lV05SLiHQUyTGLGcAG51yBc64Z+BtwWfgKzrlXnXO7zyhZCOQHyz90zq0PHhcDJUBuBGvVWdwiIgcRybDIAwrDnhcFyw7kRmC/S0KZ2QwgHtjYyWtzzWyxmS0uLS09omLTNU25yIAVye74vuJI9zGSYWGdLOu0WjO7HpgO/KzD8mHAX4DPOefa99uYc/c756Y756bn5h5Zw0MtC5GBKTExkbKysn4dGM45ysrKSExMPOxtRPJoqCJgRNjzfKC440pmdj7wXWCWc64pbHk68DzwPefcwgjWCSgsRAaq/Px8ioqKONLeib4uMTGR/Pz8w35/JMPiPeAYMxsDbAOuAa4LX8HMpgH3AbOdcyVhy+OBecBDzrknIljjHgoLkYEpFAoxZsyYaJfR50WsG8o51wp8BfgXsAZ43Dm3yszuMLNLg9V+BqQCT5jZMjN7Nlh+FXAW8Nlg+bLgcNqI2RMW9QoLEZGOInpSnnPuBeCFDstuD3t8/gHe9zDwcCRr62jvNOWtvfmxIiJHBU33EQjFxpASH6tuKBGRTigswmh+KBGRzikswuiaFiIinVNYhNE1LUREOqewCKNuKBGRzikswmQkhahuVFiIiHSksAijloWISOcUFmEykkLUN7fR0rbfNFQiIgOawiJMRrKm/BAR6YzCIozmhxIR6ZzCIky6wkJEpFMKizBqWYiIdE5hESZDV8sTEemUwiKMWhYiIp1TWITRNS1ERDqnsAgTio0hWdOUi4jsR2HRgc7iFhHZn8KiA4WFiMj+FBYd6JoWIiL7U1h0kJ6osBAR6Uhh0YEugCQisj+FRQcasxAR2Z/CooOMpBB1mqZcRGQfCosOMpLiAE35ISISTmHRga5pISKyP4VFB5ofSkRkfwqLDhQWIiL7U1h0oLAQEdmfwqKDdF3TQkRkPwqLDtSyEBHZn8Kig4S4WBJDMQoLEZEwCotO6CxuEZF9KSw64eeHao12GSIifYbCohNqWYiI7Eth0QmFhYjIvhQWndAFkERE9qWw6ISuaSEisi+FRScykkLUNLXS1u6iXYqISJ8Q0bAws9lmts7MNpjZrZ28/g0zW21my83sFTMbFfbaP82s0syei2SNncnQWdwiIvuIWFiYWSzwG2AOMBG41swmdljtfWC6c24K8CTw07DXfgbcEKn6DkZncYuI7CuSLYsZwAbnXIFzrhn4G3BZ+ArOuVedc/XB04VAfthrrwA1EazvgBQWIiL7imRY5AGFYc+LgmUHciPwYgTr6TaFhYjIvuIiuG3rZFmnI8Zmdj0wHZh1SB9gNheYCzBy5MhDre+AFBYiIvuKZMuiCBgR9jwfKO64kpmdD3wXuNQ513QoH+Ccu985N905Nz03N/eIig2nsBAR2Vckw+I94BgzG2Nm8cA1wLPhK5jZNOA+fFCURLCWQ5KusBAR2UfEwsI51wp8BfgXsAZ43Dm3yszuMLNLg9V+BqQCT5jZMjPbEyZm9gbwBHCemRWZ2UWRqrWjxFAsCXExOnRWRCQQyTELnHMvAC90WHZ72OPzD/Lej0SwtC5pfigRkb10BndDBbx5N+xYuc9izQ8lIrJXRFsWRweDV34ILQ0wdNKepWpZiIjspZZFUiYMmwqbFuyzWGEhIrKXwgJg7Cwoeg+aavcsUliIiOylsAAYMwvaW2HrO3sWKSxERPZSWACMPA1iE6DgtT2L0pNC1DRqmnIREVBYeKEkGDFjn3GL3Wdx1zSqdSEiorDYbews2LEC6nYBmvJDRCScwmK3MWf7+02vAwoLEZFwCovdhk+DhPQ9XVEKCxGRvRQWu8XGwagzoEBhISLSkcIi3NhZULEJKrcqLEREwigswo0Jrr1UsGBPWFQ3tEaxIBGRvkFhEW7wBEgZDJsWkBiKIT42Ri0LERG6GRZm9lUzSzfvD2a21MwujHRxvc4MxpwFm17H8CfmVdY3R7sqEZGo627L4vPOuWrgQiAX+BxwV8Sqiqaxs6B2J5Su5fihabxTUIZzOotbRAa27oaFBfcfBf7onPsgbFn/EjZucenU4Wwpq+f9wsro1iQiEmXdDYslZjYfHxb/MrM0oD1yZUVR1ijIGg2bFjB70lAS4mL4+/vbol2ViEhUdTcsbgRuBU5xztUDIXxXVP80ZhZsfpP0kHH+hCH8Y/l2Wtr6ZzaKiHRHd8NiJrDOOVdpZtcD3wOqIldWlI2dBU3VsH0Zl0/Lo7yumTfX74p2VSIiUdPdsPgdUG9mJwLfBrYAD0WsqmjbM27xGrOOzSUzOcQ8dUWJyADW3bBodf6QoMuAXznnfgWkRa6sKEvJgSGTYNMC4uNiuHjyMOav3kFtk07QE5GBqbthUWNmtwE3AM+bWSx+3KL/GjMLti6ClgYun5ZHY0s781ftiHZVIiJR0d2wuBpowp9vsQPIA34Wsar6grGzoK0JChdx8sgs8rOSeGZZcbSrEhGJim6FRRAQfwUyzOwSoNE513/HLABGnQ4xcVDwGjExxmVTh/Pm+lJKahqjXZmISK/r7nQfVwHvAlcCVwGLzOyTkSws6hLSfFfUB49BWwuXT82j3cFzH2yPdmUiIr2uu91Q38WfY/EZ59yngRnA9yNXVh8xYy7UFMPa5zhmSBonDE/nmWU6KkpEBp7uhkWMc64k7HnZIbz36HXMBf5s7kX3A/DxaXksL6qioLQ2unWJiPSy7v7B/6eZ/cvMPmtmnwWeB16IXFl9REwsnPKfsPVt2LGCj504HDM00C0iA053B7i/BdwPTAFOBO53zt0SycL6jGnXQygZFt3HkPREzhiXwzPvb9NMtCIyoHS7K8k595Rz7hvOua875+ZFsqg+JSkTplwNK56A+nIumzqcreWaiVZEBpaDhoWZ1ZhZdSe3GjOr7q0io27GXGhthKV/3jMT7TOa/kNEBpCDhoVzLs05l97JLc05l95bRUbdkIkw+iPw3h9ICxkXnTCUeUu36Sp6IjJg9P8jmnrKqTdBVSF8+CJfOmcctc2t3Pd6QbSrEhHpFQqL7jp2DmSMgEX3cfzQdC49cTh/emuzzugWkQFBYdFdsXFwyo2w+Q3YuZqvn38szW3t/PbVjdGuTEQk4hQWh+Kkz0BcIrx7P6NzUrjy5HweWbSVbZUN0a5MRCSiFBaHInkQTP4kLH8MGir4r/OOAeCel9dHuTARkchSWByqGTdBSz28/1fyMpP41GkjeXJpkaYAEZF+LaJhYWazzWydmW0ws1s7ef0bZrbazJab2StmNirstc+Y2frg9plI1nlIhk2BkafDovugtZkvnT2e+NgYfqnWhYj0YxELi+Bqer8B5gATgWvNbGKH1d4HpjvnpgBPAj8N3jsI+AFwKn6G2x+YWVakaj1kH/kmVG2FZQ+Tm5bA584YzT8+KGbN9oFznqKIDCyRbFnMADY45wqcc83A3/DX8N7DOfeqc64+eLoQyA8eXwS85Jwrd85VAC8BsyNY66EZfx7kz4DXfw6tTdx01jjSEuP43/kfRrsyEZGIiGRY5AGFYc+LgmUHciPw4qG818zmmtliM1tcWlp6hOUeAjM45ztQvQ2WPkRGcoibzhrLy2t2snRrRe/VISLSSyIZFtbJsk6najWz64Hp7L2ud7fe65y73zk33Tk3PTc397ALPSxjz4ZRZ/jWRUsDnztjDNkp8fz8X+s0I62I9DuRDIsiYETY83xgvwtBmNn5+CvxXeqcazqU90bV7tZF7Q5Y/EdSEuL48jnjeXtjGS+u3BHt6kREelQkw+I94BgzG2Nm8cA1wLPhK5jZNOA+fFCEX4nvX8CFZpYVDGxfGCzrW0afCWPOgjd/Ac11fHrmKCblpXP731dRVd8S7epERHpMxMLCOdcKfAX/R34N8LhzbpWZ3WFmlwar/QxIBZ4ws2Vm9mzw3nLgR/jAeQ+4I1jW95zzXagrhfd+T1xsDHddMYWK+mbufGF1tCsTEekx1l/616dPn+4WL14cnQ//yxVQ/D58bTkkpHHXi2u5d8FG/vofp3LG+Jzo1CQi0g1mtsQ5N72r9XQGd08457vQUA7v3g/A184/htHZydz29AoamtuiXJyIyJFTWPSE/JPh2Nnw1j3QWEViKJafXDGFreX13P2yzr0QkaOfwqKnnH0bNFbCwnsBmDkum2tnjOCBNwpYUVQV5eJERI6MwqKnDJ8Kx18C7/wflPrWxK1zJpCTmsAtTy2npa09ygWKiBw+hUVPuvDH/noXf7kcKgvJSApxx2WTWL29mgfe0CVYReTopbDoSYPGwA1PQ1OtD4zaUmZPGsrsE4Zy98vr+XBnTbQrFBE5LAqLnjZ0MnzqcajaBg9fAY1V3HHZCaQnhpj70GKdrCciRyWFRSSMPA2ufhhK1sAj1zA4yXHfDSexrbKBrzy6lFaNX4jIUUZhESnHnA9X3Adb34HHP8PJ+Wn8+PJJvLF+F//zz7XRrk5E5JAoLCJp0ifgkl/A+n/BM1/k6mlD+MzMUTzwxiaeXloU7epERLotLtoF9HvTPw8NlfDKD2Hzm9x+6hcpHD2JW59ewbjcVE4ckRntCkVEuqSWRW/4yDfg+qchezyxL9/O7ys+y/cSn+DWh16ipLox2tWJiHRJYdFbxp8Hn30O/vPfxIw7hxtan+aZ5i+y7LefpXnDa9Bc3+UmRESiRbPORkvZRrY+dxdDCuaRYC24mDhs2FQYNRNGnu6PqEoeFO0qRaSf6+6sswqLKPvLqx/w75f+wdWDi7gwrYCY4vehrdm/eNqXYPZPolugiPRr3Q0LDXBH2Q3nnEhzKJ0vPLeaOTlDuefbEwhtfx+W/BEW/haOv9hfkU9EJIoUFn3AjWeOAeBHz63mv4F7rp1JaPg0KFwEz30DvvAmxMVHt0gRGdA0wN1H3HjmGL5/yUReXLmD/3rkfVpiE+Gj/wu71sE7v452eSIywCks+pAbzxzD7ZdM5J+rgsAYdz5MuBQW/BTKN0W7PBEZwBQWfcznwwJj7kOLqT3nxxATBy9+G/rJwQgicvRRWPRBnz9zDHd+fBKvr9/Fxx/eTPmMm2H9fFjzj2iXJiIDlMKij/rUqaN46PMzKKlp4oK3jqcuawK8eAs06ZoYItL7FBZ92Bnjc3j2K2eQlZbMp0uuw9Vsh1d13oWI9D6FRR83KjuFeV86nYxjZvLX1nNpX/g7WoqWRbssERlgFBZHgbTEEA98ejqlp95CmUul9I/XUbbwEWjTVfdEpHcoLI4SsTHG1z92Kh+e/gtaWtvI/ucXafjZRNyCn0JtabTLE5F+TmFxlDnjoiuJ+e8l/CTrDt6rG4K9eifulxNh3hdh2xJo1yVbRaTnaSLBo1Rbu+MPbxYw71+v8rn4+VwR+wZxrfWQnA2jPwJjPgJjZkH2eDCLdrki0kdp1tkBYu2Oar7+2Ads276d74wr4LKMjSQVvQXV2/wKqUNhzFkwYy6MOCW6xYpIn6OwGECaWtu4++X13P96AbExxjXT8/nKtFgG73oXNr0OG16Bxko4djac810YNiXaJYtIH6GwGIC2ltXz29c28OSSImLMuHJ6Pl88exz5ye2w6F54+x5orIKJl8M534Hc46JdsohEmcJiACuqqOd3r23k8cWFOAefPDmfL509npHJzfDOb/x1MlrqYfJVcN7tkJEX7ZJFJEoUFkJxZQP3LdjIo+8V0tbuuGJaHl8+Zzyjkxrhrbvh3QcglASfeADGnx/tckUkChQWssfO6kbuXbCRRxZtpaWtncun5vHlc8czznbA45+GktUw6xaY9W2IiY12uSLSixQWsp+SmkYeeL2AvyzcQnNrOx87cThfOTOPY977AXzwCIw7F654AFJyol2qiPQShYUc0K7aJh54o4C/vLOF+uY2LpwwmO/lLWHkO7f7oLjyTzBixt43NFZDVRFUFfpraow+AxLSola/iPQchYV0qbyumT+9vZk/v72ZqoYWrhtZwe31/0NCfTE29myo2QlVW/0RVOFiQjDqdDj2Ijjmwv1P/Gusgl0bYNeHUFMMkz4JWaN6cc9EpLsUFtJttU2tPLJoCw+8sYmmmnLuyXiEaQnbSM4dTWjQSMgYAZkj/H1rI6x/yd9K1/gNZI3xLZHqYti1Hmp37PsBSYN8a2XsrF7fNxE5uD4RFmY2G/gVEAv83jl3V4fXzwLuBqYA1zjnngx77X+Ai4OnP3LOPXawz1JYHLnGljaeWlrEvQs2UljeQGyMcfKoLM6fMJhzjx/CuNwULLwFUbnVX8Fv/UtQvMwHSs6xkHNMcH8cuDY/iL5rPVx0J5z6BU0/ItKHRD0szCwW+BC4ACgC3gOudc6tDltnNJAO3Aw8uzsszOxi4GvAHCABWACc65yrPtDnKSx6Tnu744OiSv69toSX15SwZrv/sY/KTub8CUO4ZMowpo7I3Dc4DqapBp6+CdY9DydeB5f8EkKJEdwDEemu7oZFXARrmAFscM4VBAX9DbgM2BMWzrnNwWsdp0qdCCxwzrUCrWb2ATAbeDyC9UogJsaYNjKLaSOz+OaFx1Fc2cAra0t4Zc1O/vLOFv7w5ibys5L42InDuWTKMCYOSz94cCSkwdUPw+s/hdd+ArvW+efpw3tvp0TkiEQyLPKAwrDnRcCp3XzvB8APzOwXQDJwDmEhI71reGYSN5w2ihtOG0VVQwvzV+3gueXbuf/1An732kbG5qZwyZThXDx5GMcOSe08OGJi4OxbYcgkmHcT3DfLnz0+7hzIyO/9nRKRQxLJsOjsq2a3+rycc/PN7BTgbaAUeAdo3e8DzOYCcwFGjhx5+JVKt2Ukhbhy+giunD6C8rpm/rlyB//4oJhf/3s997yynrE5KcyZPJQ5k4ZxwvBOWhwTLoHsl+GxG+DZr/hl2eP9dOpjZ/np1RMzoWY7lG2A8o1QthHKC/whvIOP94EzdDIMngDxKb3/Q9itvR12roAhk30YivRjkRyzmAn8f865i4LntwE4537Sybp/Ap4LH+Du8PojwMPOuRcO9Hkas4iukppG5q/ayYsrt7OwoJy2dseIQUnMmTSMjxyTw8mjskiOD/tu0t7uzxzftAAKFsCWt6C5FjCIS4TWhr3rxiXCoLEQnwqla6Fp99CVQfY4Hx6DJ0Du8f6WPQ5iQ5Hd4epieOaLUPAanPUtOPd7kf08kQjpCwPccfgB7vOAbfgB7uucc6s6WfdPhIVFMDie6ZwrM7MpwCPA1GAMo1MKi76jvK6Zl1bv4IUVO3hrwy5a2x1xMcaU/AxOHZvNaWOzmT4qi5SEsPBoa4FtS/0f36ZqHw7Z43yrI2343m/uzkHlFtixEnauhB0rYOcqqNjMnoZrTMi/b/DxvsVy/CWQmttzO7jqGfjHV6GtGYZNha1vw3WP+/NORI4yUQ+LoIiP4g+NjQUedM7daWZ3AIudc88GXU3zgCygEdjhnDvBzBKBpcFmqoEvOOeWHeyzFBZ9U21TK4s3l7NoUzmLCspYXlRFa7sjNsaYnJfBaWOzOW3sIKaPHkRqwhH0ijbX+5MAS9f6W8laHyTVRWAxMPJ0mHgpTPjY4Q+sN1bDi9+GDx6F4Sf5qVEy8uAPF0BlIdy0ALJGH/4+iERBnwiL3qSwODrUN7eyZEsFiwrKWbSpjGWFlbS0+fCYkr87PDppeRwO53zrY/WzsOZZHyIA+af4sZHc4/aeE9LV9CVb3oF5c/20Jx+52U+6uLurq3wT3D8LMkfBjS/psGA5qigs5KhQ39zK0i2VLCwoY2FBGR8U+fCIizEm52cwc3d4jO4w5nE4Sj+ENX+HNf/wXVftYb2aacN9cKTk+FZKc21wq4OmWj/gnjUKPn4/jOzkoL51/4RHr4ZpN8Bl/3dkdYr0IoWFHJV2h8c7BbtYWFDOB4WVe8Y8JudnMCUvg0l5GUzOz2B8bipxsYd5FFJrsx/n2LXOd1/tWg+l66ChAhJSIT7NH2kVn+KfZ4yAmV8+eAs/ovkSAAAQu0lEQVTklR/BGz+HS38NJ3368OoS6WUKC+kX6ptbWby5goUFZSzeXMGq4irqmtsASAzFMGFYOpPzMjh+aDrHDU3j2CGppCVG+EioA2lvg4ev8F1W//ESDDvx8LZTtwu2vuO3s+Utf9jwoDEweGLYbYIfe9HUKXKEFBbSL7W3Owp21bFyWxUrgtvq4mpqm/Z2KeVlJnH80DSOG5rGpLwMThyRyfCMxO5PT3Ik6nbBfWdBTBxccIc/squhEhor/Wy8DZW++ysuEeLi/X1scF+/ywfErnV+W3GJkDfdj61UbIKSNb47bLeEDH/EV+7xew8dHjwRUgf3rRAp2wjzv+8Ph778d5A2NNoVSRiFhQwYzjmKKhpYt6OGdTtr/P2OGjaW1tLa7n+/c1LjmZKfyYn5mUwZkcGJ+ZkMSomPTEFFi+GPc/yhtbtZLCRmQFKmD5LWpuDW6NdrbfTnkYw41U//Pup0GD4N4hL23XZ9uQ+NktXBba2f/behYu86SVkw4jQ45nwYf0H0podvqoHXfwbv/NYHn2vz3XhX/hlGzYxOTb2pshBWPgktjXD6f/nuzD5IYSEDXlNrG2u317C8qJJlhVUsL6pkQ2ktu3/l8zKTmByMf0zKy2ByXkbPBUh1MdSX+bPRkzJ9EHT1bd+5w2sROAe1JT40StZCySp/omPlFv96znFwzAX+OusjZ0b+aK32dljxOLx0O9TuhKnX+6ld6svgset9XRfeCafe1Pn+lqyBN/4X1jwHo8+EqdfCcRcfHUeZ1ZfD6mdg+RP+/BsAzB9SfcUDMOKUaFbXKYWFSCdqm1pZUVTFim2VrNhWzcptVWzaVbfn9eEZiRw7NI3jhqRx7BDflTV+cCqJoaPs2uTO+elS1r8EG16CzW/6FkxMnA+PoZNh2BR/P2QSJA/qeputTf7claLFsGO5P38lMcPfEtL9fVw8LLwXit6FvJNhzk8hP+zvUGMVzPsCrHsBJl8JH/vV3ilbit+H138Oa5+DUIqfGmbzW/5cmcQMmPQJP2tx/vTodLOVrIF37/ddiaFkH15xiRBK8i3AbUv9z7u9xR+OPfkqmPxJ33X49E1Qvc2f7X/WtyA2kjMtHRqFhUg3VTW0sKq4ihVFVazZXs26nbVsLK2ludVPhhxjMCo7hWOHpPoQCcJkdE4KocM9Gqu3NdfBpjf8H/EdK2D78n0vUpU61I8lpA6BtCH+PnWI/0O4fTlsW+zft7trLWUwxMT6ExVb6vb9rJRcOP+HcOK1nc+Z1d4Ob/4C/v1jP8Zy9i2w9CHY8LIPhVO/4G/Jg/y6m1+HZY/482VaG/wf4qmfgqnX+fGZg2mq9eFTXgBpwyA9D9KD+6Ss7oVO4Xu+3nUv+JBIG+a7DVsa9t7j/PJJn4ApV8HQKftfPfKFb8Pyv/lxqCvu9zMUdNRY5Y/Sa6oNtt/gu7FaG3xYD53suyp7MCwVFiJHoLWtnS3l9XwYNg7y4c4aNu2qIxgGIRRrjM1JZVR2MiMHJTMyO5kRg5IZkZVMflZS32+N1Jb4ANixIrjC4c69t7pScMGVA0LJfvwk72R/QmP+9H3Pgm9r8eMTjZX+ftC47vXPb3gFnrrRj7ck5/hDk0/5D0hM73z9xmrfxfP+X6FwoW8lHTsbTvoMjD/PhxdAWytseg0+eMwHRUt959uLS/QzHg+e4CeDHHICDJ3kT64E2PhvePOXsPkN35146hd811nHVphzPkRj47v+I77yKXju6/5ndta3/LKyjcGEmRv8z70rWaNhytX+1lngHCKFhUgENLa0sbG0lg931rBuRy3rd9awtbyereX1NLXuvSyLGYzOTuGE4elMystg0vAMThieTlakBtV7WnubP7Krqcb/cYpUt0lloe8im3gZxCd3/32lH8L7D8GyR/1RZOl5vqXR0gArnvCBl5gBJ3wcplzjg66uBKq3++6gmuC+Yos/QbO8gD1zi8WnQUq2/4afNgxmfgVO/mzPDVBXbfOTUG5a4J+nDvEBmx3cBo0NuvSSfFdXKNkHW0ycnztt+d/8mBTOh/eUq32LpjtdiZ1QWIj0IuccpbVNFAbBsaWsnrXba1hZXEVRxd4ZdPOzkjhmcCojBwWtkEHJex4f0dxYA1VrM3z4YtCN9UrQ2rjI/wE99qL9jyY7kOY6Pyaxc6WfpLJyi5+A8sRrur+NQ9He7gMqdfCBW1IHU13sQ/GDv/mj4nKPhy8vOqxSFBYifURFXTOriqtZWVzFym1VFJTWUVheT03TvpMoZySFGJyWwOD0BIakJZKbnsDgtESGpicyKjuZMTkpRz5fVn9Ws9MPsCdlRbuS3uOc70asK/VdcYdBYSHShznnqGpoobC8ga3l9RRW1LOtooGSmkZKapooqW6itKaJ5rZ9rzg8JD2BMTkpe24jByWTn+XHS9Kjdea6HNX6wjW4ReQAzIzM5Hgyk+OZnJ/R6TrOOSrrWyiuamBLWT2bdtXtuf1r1U7K65r3WT8jKRR0aSX5QfbdXVxZSeRlJZEQ18cH3KVPU1iI9FFmRlZKPFkp8ZwwfP9A8S2Ten+rqN/TSlm7o4aX15TsOfTXbwuGpicyOC2B9KQQaYlxpCWESE+KIy0xRFZyiOGZPlTyMpOiN7+W9FkKC5GjVEZSiIxgFt6O2tsdJTVNQYj4QffC8gZ21TZR3djC9qpGqhtaqGlspaGlbb/3pyXGkZfpgyMnNYFBqfFkp8STnRpPdkoC2anxjByUrFAZQBQWIv1QTIwxNCORoRmJnDL64IdUtrS1U17XzLbKBrZVNFBc2cC2yt33jawsrqKstnnPPFvhBqclMDY3hbG5qYzLTWVsbgrpiXG0O2hrd7Q7h3PQ7hzJ8bHkZyWTm5pATEwfmuhQukVhITLAhWJjGJKeyJD0RE4a2fmRRM45qhtaKatroqyumdKaJjaX1VFQWkdBaS3PL99OVUNLtz4vPi6G/Kwk8rP8eMrwzCTfSkoKkR7c775lJoUULH2EwkJEumRmZCSHyEgOMTZ3/9edc5TXNVOwq46G5jZizIgx38LZ/bimsZWiinoKKxr8fXkDy4sqqaw/cMjExhiDUuLJSU0gJzWe3NQEctMSGJaRyIjgSLD8rCQdUtwL9BMWkSNmZmSnJpCdeugnsDW2tFHd0EJVcKtu9PeV9S3sqm1iV02zv69toqC0jtLapn0G7wEGpcSTn5VEakIczoHD+WlZgi6wxFAsQzMSGRZ0zQ3PSNpzn54U1zvXOjnKKSxEJKoSQ7EkhmIZnN69Kcidc+yqbaawop6isFZKUUX9nlYN/j9iYow4M2qbWnlrwy52VjfSceglJT52z1Fg/j6Z4ZmJpCbEkRSKJTE+lqSQvyWGYomL9a2lWDMsBmLNP0+Ii+nXXWYKCxE5qpgZuWm+O+pAYywH0trWTmltE9urGtlR1UhxZQNFYYP67xcevFvsYGLMH6GWlRxPZnKIQSn+PJrMYCwmLdEfppwe3KclxhEfF0N8bAyh4D4+LoaE4NbXWjsKCxEZMOJiYxiWkcSwjKQDrlPb1MqOqgbqmtpobGmjoWXvfX1zmz/Kq913c7U7f8RXW7u/XnxFfTMV9S1U1jdTXNnIquJqKutbOj08+WDi42LISt4bPFnJ/nybIWmJDM9MJC/THxgwNCOx12Y3VliIiIRJTYhj/OC0Ht1mS1s7tY2t1DS2Ut3ox2VqG1tpbmunpa2d5lZ/awpu1Q0t+wTP+pJaKuqaKetw1j5ATmoCM8dl8+trp/VozR0pLEREIiwUG7PnbPwj0dTaxo6qxuA8GN+Ntq2igezUyE99r7AQETlKJMTFMio7hVHZKb3+2UfJNSFFRCSaFBYiItIlhYWIiHRJYSEiIl1SWIiISJcUFiIi0iWFhYiIdElhISIiXTLn9r/61dHIzEqBLUewiRxgVw+VczTRfg8s2u+BpTv7Pco518lVSvbVb8LiSJnZYufc9GjX0du03wOL9ntg6cn9VjeUiIh0SWEhIiJdUljsdX+0C4gS7ffAov0eWHpsvzVmISIiXVLLQkREuqSwEBGRLg34sDCz2Wa2zsw2mNmt0a4nkszsQTMrMbOVYcsGmdlLZrY+uM+KZo09zcxGmNmrZrbGzFaZ2VeD5f19vxPN7F0z+yDY7x8Gy8eY2aJgvx8zs8hfYi0KzCzWzN43s+eC5wNlvzeb2QozW2Zmi4NlPfK7PqDDwsxigd8Ac4CJwLVmNjG6VUXUn4DZHZbdCrzinDsGeCV43p+0At90zk0ATgO+HPw/7u/73QSc65w7EZgKzDaz04D/AX4Z7HcFcGMUa4ykrwJrwp4PlP0GOMc5NzXs/Ioe+V0f0GEBzAA2OOcKnHPNwN+Ay6JcU8Q4514Hyjssvgz4c/D4z8DlvVpUhDnntjvnlgaPa/B/QPLo//vtnHO1wdNQcHPAucCTwfJ+t98AZpYPXAz8PnhuDID9Poge+V0f6GGRBxSGPS8Klg0kQ5xz28H/YQUGR7meiDGz0cA0YBEDYL+DrphlQAnwErARqHTOtQar9Nff97uBbwPtwfNsBsZ+g/9CMN/MlpjZ3GBZj/yux/VQgUcr62SZjiXuh8wsFXgK+Jpzrtp/2ezfnHNtwFQzywTmARM6W613q4osM7sEKHHOLTGzs3cv7mTVfrXfYc5wzhWb2WDgJTNb21MbHugtiyJgRNjzfKA4SrVEy04zGwYQ3JdEuZ4eZ2YhfFD81Tn3dLC43+/3bs65SuA1/JhNppnt/pLYH3/fzwAuNbPN+G7lc/Etjf6+3wA454qD+xL8F4QZ9NDv+kAPi/eAY4IjJeKBa4Bno1xTb3sW+Ezw+DPA36NYS48L+qv/AKxxzv0i7KX+vt+5QYsCM0sCzseP17wKfDJYrd/tt3PuNudcvnNuNP7f87+dc5+in+83gJmlmFna7sfAhcBKeuh3fcCfwW1mH8V/84gFHnTO3RnlkiLGzB4FzsZPW7wT+AHwDPA4MBLYClzpnOs4CH7UMrMzgTeAFeztw/4OftyiP+/3FPxgZiz+S+Hjzrk7zGws/hv3IOB94HrnXFP0Ko2coBvqZufcJQNhv4N9nBc8jQMecc7daWbZ9MDv+oAPCxER6dpA74YSEZFuUFiIiEiXFBYiItIlhYWIiHRJYSEiIl1SWIj0AWZ29u4ZUkX6IoWFiIh0SWEhcgjM7PrgOhHLzOy+YLK+WjP7XzNbamavmFlusO5UM1toZsvNbN7u6wiY2Xgzezm41sRSMxsXbD7VzJ40s7Vm9lcbCBNYyVFDYSHSTWY2AbgaP1nbVKAN+BSQAix1zp0ELMCfGQ/wEHCLc24K/gzy3cv/CvwmuNbE6cD2YPk04Gv4a6uMxc9zJNInDPRZZ0UOxXnAycB7wZf+JPykbO3AY8E6DwNPm1kGkOmcWxAs/zPwRDB3T55zbh6Ac64RINjeu865ouD5MmA08Gbkd0ukawoLke4z4M/Oudv2WWj2/Q7rHWwOnYN1LYXPVdSG/n1KH6JuKJHuewX4ZHCtgN3XNh6F/3e0e0bT64A3nXNVQIWZfSRYfgOwwDlXDRSZ2eXBNhLMLLlX90LkMOibi0g3OedWm9n38FciiwFagC8DdcAJZrYEqMKPa4CfDvreIAwKgM8Fy28A7jOzO4JtXNmLuyFyWDTrrMgRMrNa51xqtOsQiSR1Q4mISJfUshARkS6pZSEiIl1SWIiISJcUFiIi0iWFhYiIdElhISIiXfp/zbSsG6HxfA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"traing consumed: \" + str(timeTrain) + \" seconds\")\n",
    "plotProgress(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the encoding and decoding results of testing data, and get the mean/std of the encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encodeTest = encoder.predict(xTestNoise)\n",
    "decodeTest = decoder.predict(encodeTest)\n",
    "meanEncTest = np.mean(encodeTest, axis=0)\n",
    "stdEncTest = np.std(encodeTest, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare original digitals with the decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the size of pixel is not squared!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d1f08831742d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplotCompDecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecodeTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxNoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxTestNoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\workspaces\\autoencoder\\util\\util.py\u001b[0m in \u001b[0;36mplotCompDecode\u001b[1;34m(x, decode, n, xNoise, sizeDigit)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'the size of pixel is not squared!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0msizeDigit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: the size of pixel is not squared!"
     ]
    }
   ],
   "source": [
    "plotCompDecode(xTest, decodeTest, xNoise=xTestNoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the scatter of the encoding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "\n",
    "plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "scoreSilh = silhouette_score(encodeTest, yTest)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the decoding results from the encoding scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timeTrain, history.history[\"loss\"][numEpochs-1], history.history[\"val_loss\"][numEpochs-1], scoreSilh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, _), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
