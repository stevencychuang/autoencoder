{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.metrics import binary_accuracy\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import *\n",
    "from util import importNotebook\n",
    "from module.autoencoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "class TestAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 512\n",
    "    sizeKernel = 3\n",
    "    layDenEnc = [32, 8]\n",
    "    nameOptim = 'adam'\n",
    "    pathTempBest = '../model/temp/'\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype('float32') / 255.\n",
    "    xTest = xTest.astype('float32') / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "    dimInput = np.prod(xTrain.shape[1:])\n",
    "    xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "    xTest = xTest.reshape((numTest, dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        ae = AE(self.dimInput, layDenEnc=self.layDenEnc)\n",
    "        ae.encoder.summary()\n",
    "        ae.decoder.summary()\n",
    "        ae.autoencoder.summary()\n",
    "        self.ae = ae\n",
    "        \n",
    "    def test_specific_decode(self):\n",
    "        ae = AE(self.dimInput, layDenEnc=self.layDenEnc, layDenDec=[1, 4, 16])\n",
    "        ae.fit(self.xTrain, self.xTest, \n",
    "               numEpochs=5,\n",
    "               patience=1,\n",
    "               sizeBatch=1024,\n",
    "               metrics=[\"binary_accuracy\"],\n",
    "               pathTempBest=self.pathTempBest)\n",
    "        ae.encoder.summary()\n",
    "        ae.decoder.summary()\n",
    "        ae.autoencoder.summary()\n",
    "\n",
    "    def test_fit(self):\n",
    "        history, timeTrain = self.ae.fit(self.xTrain, self.xTest, \n",
    "                                         numEpochs=self.numEpochs,\n",
    "                                         sizeBatch=self.sizeBatch,\n",
    "                                         pathTempBest=self.pathTempBest)\n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        history, timeTrain = self.ae.fit(self.xTrain, self.xTest, \n",
    "                                          numEpochs=20,\n",
    "                                          patience=1,\n",
    "                                          sizeBatch=self.sizeBatch,\n",
    "                                          metrics=[\"binary_accuracy\"],\n",
    "                                          pathTempBest=self.pathTempBest)\n",
    "        # print the binary accuracy of testing dataset for verifying best model\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.xTest, self.ae.autoencoder.predict(self.xTest))).mean())\n",
    "        \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        self.ae.encoder.save('../model/test/AE/encoder.h5')\n",
    "        self.ae.decoder.save('../model/test/AE/decoder.h5')\n",
    "\n",
    "    def test_save(self):\n",
    "        self.ae.save('../model/test/AE/ae')\n",
    "        \n",
    "    def test_load_seperate(self):\n",
    "        encoder = keras.models.load_model('../model/test/AE/encoder.h5')\n",
    "        decoder = keras.models.load_model('../model/test/AE/decoder.h5')\n",
    "#         autoencoder = keras.models.load_model('./temp/autoencoder.h5', custom_objects={'lossae': lossae})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "#         decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "#         Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        encoder, decoder, autoencoder = AE.load('../model/test/AE/ae')\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        ae = self.ae\n",
    "        encoder = ae.encoder\n",
    "        decoder = ae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class TestConvAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 512\n",
    "    layDenEnc = [8]\n",
    "    layConvEnc = [4, 16]\n",
    "    nameOptim = 'adam'\n",
    "    pathTempBest = '../model/temp/'\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype('float32') / 255.\n",
    "    xTest = xTest.astype('float32') / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "    dimInput = [*sizeDigit, 1]\n",
    "    xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "    xTest = xTest.reshape((numTest, *dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        convAE = ConvAE(self.dimInput, layDenEnc=self.layDenEnc, layConvEnc=layConvEnc)\n",
    "        convAE.encoder.summary()\n",
    "        convAE.decoder.summary()\n",
    "        convAE.autoencoder.summary()\n",
    "        self.convAE = convAE\n",
    "        \n",
    "    def test_specific_decode(self):\n",
    "        convAE = ConvAE(self.dimInput, layDenEnc=self.layDenEnc, layDenDec=[1, 4, 16])\n",
    "        convAE.fit(self.xTrain, self.xTest, \n",
    "                   numEpochs=5,\n",
    "                   patience=1,\n",
    "                   sizeBatch=1024,\n",
    "                   metrics=[\"binary_accuracy\"],\n",
    "                   pathTempBest=self.pathTempBest)\n",
    "        convAE.encoder.summary()\n",
    "        convAE.decoder.summary()\n",
    "        convAE.autoencoder.summary()\n",
    "\n",
    "    def test_fit(self):\n",
    "        history, timeTrain = self.convAE.fit(self.xTrain, self.xTest, \n",
    "                                         numEpochs=self.numEpochs,\n",
    "                                         sizeBatch=self.sizeBatch,\n",
    "                                         pathTempBest=self.pathTempBest)\n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        history, timeTrain = self.convAE.fit(self.xTrain, self.xTest, \n",
    "                                          numEpochs=20,\n",
    "                                          patience=1,\n",
    "                                          sizeBatch=self.sizeBatch,\n",
    "                                          metrics=[\"binary_accuracy\"],\n",
    "                                          pathTempBest=self.pathTempBest)\n",
    "        # print the binary accuracy of testing dataset for verifying best model\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.xTest, self.convAE.autoencoder.predict(self.xTest))).mean())\n",
    "        \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        self.convAE.encoder.save('../model/test/ConvAE/encoder.h5')\n",
    "        self.convAE.decoder.save('../model/test/ConvAE/decoder.h5')\n",
    "\n",
    "    def test_save(self):\n",
    "        self.convAE.save('../model/test/ConvAE/convAE')\n",
    "        \n",
    "    def test_load_seperate(self):\n",
    "        encoder = keras.models.load_model('../model/test/ConvAE/encoder.h5')\n",
    "        decoder = keras.models.load_model('../model/test/ConvAE/decoder.h5')\n",
    "#         autoencoder = keras.models.load_model('./temp/autoencoder.h5', custom_objects={'lossae': lossae})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "#         decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "#         Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        encoder, decoder, autoencoder = ConvAE.load('../model/test/ConvAE/convAE')\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        ae = self.convAE\n",
    "        encoder = ae.encoder\n",
    "        decoder = ae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "class TestVAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 512\n",
    "    sizeKernel = 3\n",
    "    layDenEnc = [32, 8]\n",
    "    ratRecon = 1\n",
    "    nameOptim = 'adam'\n",
    "    pathTempBest = '../model/temp/'\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype('float32') / 255.\n",
    "    xTest = xTest.astype('float32') / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "    dimInput = np.prod(xTrain.shape[1:])\n",
    "    xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "    xTest = xTest.reshape((numTest, dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        vae = VAE(self.dimInput, layDenEnc=self.layDenEnc, ratRecon=self.ratRecon)\n",
    "        vae.encoder.summary()\n",
    "        vae.decoder.summary()\n",
    "        vae.autoencoder.summary()\n",
    "        self.vae = vae\n",
    "\n",
    "    def test_fit(self):\n",
    "        history, timeTrain = self.vae.fit(self.xTrain, self.xTest, \n",
    "                                          numEpochs=self.numEpochs,\n",
    "                                          sizeBatch=self.sizeBatch,\n",
    "                                          pathTempBest=self.pathTempBest)\n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        history, timeTrain = self.vae.fit(self.xTrain, self.xTest, \n",
    "                                          numEpochs=20,\n",
    "                                          patience = 1,\n",
    "                                          sizeBatch=self.sizeBatch,\n",
    "                                          metrics=[\"binary_accuracy\"],\n",
    "                                          pathTempBest=self.pathTempBest)\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.xTest, self.vae.autoencoder.predict(self.xTest))).mean())\n",
    "        \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        self.vae.encoder.save('../model/test/VAE/encoder.h5')\n",
    "        self.vae.decoder.save('../model/test/VAE/decoder.h5')\n",
    "\n",
    "    def test_save(self):\n",
    "        self.vae.save('../model/test/VAE/vae')\n",
    "        \n",
    "    def test_load_seperate(self):\n",
    "        encoder = keras.models.load_model('../model/test/VAE/encoder.h5')\n",
    "        decoder = keras.models.load_model('../model/test/VAE/decoder.h5')\n",
    "#         autoencoder = keras.models.load_model('./temp/autoencoder.h5', custom_objects={'lossVAE': lossVAE})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "#         decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "#         Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        encoder, decoder, autoencoder = VAE.load('../model/test/VAE/vae')\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        vae = self.vae\n",
    "        encoder = vae.encoder\n",
    "        decoder = vae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class TestConvVAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 512\n",
    "    sizeKernel = 3\n",
    "    layDenEnc = [8]\n",
    "    layConvEnc = [4, 16]\n",
    "    ratRecon = 1\n",
    "    nameOptim = 'adam'\n",
    "    pathTempBest = '../model/temp/'\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype('float32') / 255.\n",
    "    xTest = xTest.astype('float32') / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "    dimInput = [*sizeDigit, 1]\n",
    "    xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "    xTest = xTest.reshape((numTest, *dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        convVAE = ConvVAE(self.dimInput, layDenEnc=self.layDenEnc, layConvEnc=self.layConvEnc, ratRecon=self.ratRecon)\n",
    "        convVAE.encoder.summary()\n",
    "        convVAE.decoder.summary()\n",
    "        convVAE.autoencoder.summary()\n",
    "        self.convVAE = convVAE\n",
    "\n",
    "    def test_fit(self):\n",
    "        history, timeTrain = self.convVAE.fit(self.xTrain, self.xTest, \n",
    "                                              numEpochs=self.numEpochs,\n",
    "                                              sizeBatch=self.sizeBatch,\n",
    "                                              pathTempBest=self.pathTempBest)\n",
    "\n",
    "        \n",
    "    def test_save(self):\n",
    "        self.convVAE.save('../model/test/ConvVAE/convVAE')\n",
    "        \n",
    "    def test_load(self):\n",
    "        encoder, decoder, autoencoder = ConvVAE.load('../model/test/ConvVAE/convVAE')\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "    def test_prediction(self):\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        convVAE = self.convVAE\n",
    "        encoder = convVAE.encoder\n",
    "        decoder = convVAE.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)  \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.3694 - binary_accuracy: 0.7618 - val_loss: 0.2478 - val_binary_accuracy: 0.7655\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24777, saving model to ../model/temp//AutoEncoder1536659545.936687.hdf5\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2445 - binary_accuracy: 0.7950 - val_loss: 0.2282 - val_binary_accuracy: 0.7798\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24777 to 0.22823, saving model to ../model/temp//AutoEncoder1536659545.936687.hdf5\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2386 - binary_accuracy: 0.7952 - val_loss: 0.2248 - val_binary_accuracy: 0.7887\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22823 to 0.22483, saving model to ../model/temp//AutoEncoder1536659545.936687.hdf5\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2361 - binary_accuracy: 0.7950 - val_loss: 0.2245 - val_binary_accuracy: 0.7959\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22483 to 0.22451, saving model to ../model/temp//AutoEncoder1536659545.936687.hdf5\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2345 - binary_accuracy: 0.7952 - val_loss: 0.2263 - val_binary_accuracy: 0.7921\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22451\n",
      "Epoch 00005: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 8)         32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          2336      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 12552     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 15,178\n",
      "Trainable params: 15,082\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1568)              14112     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 8)         2312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 8)         32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        2336      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 19,265\n",
      "Trainable params: 19,169\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 15178     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         19265     \n",
      "=================================================================\n",
      "Total params: 34,443\n",
      "Trainable params: 34,251\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     testAE = TestAE()\n",
    "#     testAE.test_init()\n",
    "#     testAE.test_fit()\n",
    "# #     testAE.test_fit_check_best()\n",
    "#     testAE.test_prediction()\n",
    "#     testAE.test_save()\n",
    "#     testAE.test_load()\n",
    "#     testAE.test_specific_decode()\n",
    "    \n",
    "    testConvAE = TestConvAE()\n",
    "#     testConvAE.test_init()\n",
    "#     testConvAE.test_fit()\n",
    "# #     testConvAE.test_fit_check_best()\n",
    "#     testConvAE.test_prediction()\n",
    "#     testConvAE.test_save()\n",
    "#     testConvAE.test_load()\n",
    "    testConvAE.test_specific_decode()\n",
    "    \n",
    "#     testVAE = TestVAE()\n",
    "#     testVAE.test_init()\n",
    "#     testVAE.test_fit()\n",
    "# #     testVAE.test_fit_check_best()\n",
    "#     testVAE.test_prediction()\n",
    "#     testVAE.test_save()\n",
    "#     testVAE.test_load()\n",
    "    \n",
    "#     testConv = TestConvVAE()\n",
    "#     testConv.test_init()\n",
    "#     testConv.test_fit()\n",
    "#     testConv.test_prediction()\n",
    "#     testConv.test_save()\n",
    "#     testConv.test_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# import numpy as np\n",
    "# numEpochs = 2\n",
    "# sizeBatch = 128\n",
    "# sizeKernel = 3\n",
    "# layerDense = [16, 2]\n",
    "# ratRecon = 1\n",
    "# nameOptim = 'adam'\n",
    "# modelPath = '../model/temp/'\n",
    "# patience = 3\n",
    "# stdEps = 1.0\n",
    "\n",
    "# (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "# xTrain = xTrain.astype('float32') / 255.\n",
    "# xTest = xTest.astype('float32') / 255.\n",
    "# numTrain = len(xTrain)\n",
    "# numTest = len(xTest)\n",
    "# sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "# dimInput = np.prod(xTrain.shape[1:])\n",
    "# xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "# xTest = xTest.reshape((numTest, dimInput))\n",
    "# print(xTrain.shape)\n",
    "# print(xTest.shape)\n",
    "\n",
    "\n",
    "# layerDense=[64, 2] \n",
    "# actDense='relu'\n",
    "# ratRecon=0.998\n",
    "# dimEncode = layerDense[-1]\n",
    "\n",
    "# inputs = Input(shape=(dimInput,)) \n",
    "# x = inputs\n",
    "\n",
    "# # Stack of Dense layers\n",
    "# for numFilt in layerDense[:-1]:\n",
    "#     x = Dense(numFilt, activation=actDense)(x)\n",
    "# zMean = Dense(dimEncode)(x)\n",
    "# zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "# def sampling(args):\n",
    "#     zMean, zSigmaLog = args\n",
    "#     epsilon = K.random_normal(shape=(K.shape(zMean)[0], K.shape(zMean)[1]),\n",
    "#                               mean=0., stddev=stdEps)\n",
    "#     return zMean + K.exp(zSigmaLog) * epsilon  \n",
    "    \n",
    "# # Construct the latent as the output and build the encorder pipeline\n",
    "# z = Lambda(sampling)([zMean, zSigmaLog])\n",
    "# encoder = Model(inputs, z, name='encoder')\n",
    "\n",
    "# # Build the Decoder Model\n",
    "# inputLatent = Input(shape=(dimEncode,), name='decoder_input')\n",
    "# x = inputLatent\n",
    "# for numFilt in layerDense[-2::-1]:\n",
    "#     x = Dense(numFilt, activation=actDense)(x)\n",
    "\n",
    "# # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "# outputs = Dense(dimInput, activation='sigmoid', name='decoder_output')(x)\n",
    "# decoder = Model(inputLatent, outputs, name='decoder')\n",
    "\n",
    "# autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "\n",
    "# def lossVAE(tensorInput, tensorDecode):\n",
    "#     zMean = zMean\n",
    "#     zSigmaLog = zSigmaLog\n",
    "#     ratRecon = ratRecon\n",
    "\n",
    "#     lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "# #         lossRecon =  metrics.mean_squared_error(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "#     lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "#     return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "\n",
    "# autoencoder.compile(optimizer=nameOptim, loss=lossVAE)\n",
    "\n",
    "# history = autoencoder.fit(xTrain, xTrain,\n",
    "#                           epochs=numEpochs,\n",
    "#                           batch_size=sizeBatch, shuffle=True,\n",
    "#                           callbacks=callbacks,\n",
    "#                           validation_data=(xValid, xValid)\n",
    "#                          )\n",
    "# vae.encoder.save('./encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
