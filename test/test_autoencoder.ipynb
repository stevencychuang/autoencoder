{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.metrics import binary_accuracy\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import *\n",
    "from util import importNotebook\n",
    "from module.autoencoder import VAE, ConvVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestVAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 128\n",
    "    sizeKernel = 3\n",
    "    layerDense = [16, 2]\n",
    "    ratRecon = 1\n",
    "    nameOptim = 'adam'\n",
    "    pathTempBest = '../model/temp/'\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype('float32') / 255.\n",
    "    xTest = xTest.astype('float32') / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "    dimInput = np.prod(xTrain.shape[1:])\n",
    "    xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "    xTest = xTest.reshape((numTest, dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        vae = VAE(self.dimInput, layerDense=self.layerDense, ratRecon=self.ratRecon)\n",
    "        vae.encoder.summary()\n",
    "        vae.decoder.summary()\n",
    "        vae.autoencoder.summary()\n",
    "        self.vae = vae\n",
    "\n",
    "    def test_fit(self):\n",
    "        history, timeTrain = self.vae.fit(self.xTrain, self.xTest, \n",
    "                                          numEpochs=self.numEpochs,\n",
    "                                          sizeBatch=self.sizeBatch,\n",
    "                                          pathTempBest=self.pathTempBest)\n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        history, timeTrain = self.vae.fit(self.xTrain, self.xTest, \n",
    "                                          numEpochs=20,\n",
    "                                          patience = 1,\n",
    "                                          sizeBatch=self.sizeBatch,\n",
    "                                          metrics=[\"binary_accuracy\"],\n",
    "                                          pathTempBest=self.pathTempBest)\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.xTest, self.vae.autoencoder.predict(self.xTest))).mean())\n",
    "        \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        self.vae.encoder.save('../model/test/VAE/encoder.h5')\n",
    "        self.vae.decoder.save('../model/test/VAE/decoder.h5')\n",
    "\n",
    "    def test_save(self):\n",
    "        self.vae.save('../model/test/VAE/vae')\n",
    "        \n",
    "    def test_load_seperate(self):\n",
    "        encoder = keras.models.load_model('../model/test/VAE/encoder.h5')\n",
    "        decoder = keras.models.load_model('../model/test/VAE/decoder.h5')\n",
    "#         autoencoder = keras.models.load_model('./temp/autoencoder.h5', custom_objects={'lossVAE': lossVAE})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "#         decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "#         Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        encoder, decoder, autoencoder = VAE.load('../model/test/VAE/vae')\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        vae = self.vae\n",
    "        encoder = vae.encoder\n",
    "        decoder = vae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestConvVAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 128\n",
    "    sizeKernel = 3\n",
    "    layerDense = [16, 2]\n",
    "    layerConv = [4, 16]\n",
    "    ratRecon = 1\n",
    "    nameOptim = 'adam'\n",
    "    pathTempBest = '../model/temp/'\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype('float32') / 255.\n",
    "    xTest = xTest.astype('float32') / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "    dimInput = [*xTrain.shape[1:], 1]\n",
    "    xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "    xTest = xTest.reshape((numTest, *dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        convVAE = ConvVAE(self.dimInput, layerDense=self.layerDense, layerConv=self.layerConv, ratRecon=self.ratRecon)\n",
    "        convVAE.encoder.summary()\n",
    "        convVAE.decoder.summary()\n",
    "        convVAE.autoencoder.summary()\n",
    "        self.convVAE = convVAE\n",
    "\n",
    "    def test_fit(self):\n",
    "        history, timeTrain = self.convVAE.fit(self.xTrain, self.xTest, \n",
    "                                              numEpochs=self.numEpochs,\n",
    "                                              sizeBatch=self.sizeBatch,\n",
    "                                              pathTempBest=self.pathTempBest)\n",
    "\n",
    "        \n",
    "    def test_save(self):\n",
    "        self.convVAE.save('../model/test/ConvVAE/convVAE')\n",
    "        \n",
    "    def test_load(self):\n",
    "        encoder, decoder, autoencoder = ConvVAE.load('../model/test/ConvVAE/convVAE')\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.xTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "    def test_prediction(self):\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        convVAE = self.convVAE\n",
    "        encoder = convVAE.encoder\n",
    "        decoder = convVAE.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)  \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    testVAE = TestVAE()\n",
    "    testVAE.test_init()\n",
    "    testVAE.test_fit()\n",
    "#     testVAE.test_fit_check_best()\n",
    "    testVAE.test_prediction()\n",
    "    testVAE.test_save()\n",
    "    testVAE.test_load()\n",
    "    \n",
    "    testConv = TestConvVAE()\n",
    "    testConv.test_init()\n",
    "    testConv.test_fit()\n",
    "    testConv.test_prediction()\n",
    "    testConv.test_save()\n",
    "    testConv.test_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# import numpy as np\n",
    "# numEpochs = 2\n",
    "# sizeBatch = 128\n",
    "# sizeKernel = 3\n",
    "# layerDense = [16, 2]\n",
    "# ratRecon = 1\n",
    "# nameOptim = 'adam'\n",
    "# modelPath = '../model/temp/'\n",
    "# patience = 3\n",
    "# stdEps = 1.0\n",
    "\n",
    "# (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "# xTrain = xTrain.astype('float32') / 255.\n",
    "# xTest = xTest.astype('float32') / 255.\n",
    "# numTrain = len(xTrain)\n",
    "# numTest = len(xTest)\n",
    "# sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "# dimInput = np.prod(xTrain.shape[1:])\n",
    "# xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "# xTest = xTest.reshape((numTest, dimInput))\n",
    "# print(xTrain.shape)\n",
    "# print(xTest.shape)\n",
    "\n",
    "\n",
    "# layerDense=[64, 2] \n",
    "# actDense='relu'\n",
    "# ratRecon=0.998\n",
    "# dimEncode = layerDense[-1]\n",
    "\n",
    "# inputs = Input(shape=(dimInput,)) \n",
    "# x = inputs\n",
    "\n",
    "# # Stack of Dense layers\n",
    "# for numFilt in layerDense[:-1]:\n",
    "#     x = Dense(numFilt, activation=actDense)(x)\n",
    "# zMean = Dense(dimEncode)(x)\n",
    "# zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "# def sampling(args):\n",
    "#     zMean, zSigmaLog = args\n",
    "#     epsilon = K.random_normal(shape=(K.shape(zMean)[0], K.shape(zMean)[1]),\n",
    "#                               mean=0., stddev=stdEps)\n",
    "#     return zMean + K.exp(zSigmaLog) * epsilon  \n",
    "    \n",
    "# # Construct the latent as the output and build the encorder pipeline\n",
    "# z = Lambda(sampling)([zMean, zSigmaLog])\n",
    "# encoder = Model(inputs, z, name='encoder')\n",
    "\n",
    "# # Build the Decoder Model\n",
    "# inputLatent = Input(shape=(dimEncode,), name='decoder_input')\n",
    "# x = inputLatent\n",
    "# for numFilt in layerDense[-2::-1]:\n",
    "#     x = Dense(numFilt, activation=actDense)(x)\n",
    "\n",
    "# # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "# outputs = Dense(dimInput, activation='sigmoid', name='decoder_output')(x)\n",
    "# decoder = Model(inputLatent, outputs, name='decoder')\n",
    "\n",
    "# autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "\n",
    "# def lossVAE(tensorInput, tensorDecode):\n",
    "#     zMean = zMean\n",
    "#     zSigmaLog = zSigmaLog\n",
    "#     ratRecon = ratRecon\n",
    "\n",
    "#     lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "# #         lossRecon =  metrics.mean_squared_error(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "#     lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "#     return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "\n",
    "# autoencoder.compile(optimizer=nameOptim, loss=lossVAE)\n",
    "\n",
    "# history = autoencoder.fit(xTrain, xTrain,\n",
    "#                           epochs=numEpochs,\n",
    "#                           batch_size=sizeBatch, shuffle=True,\n",
    "#                           callbacks=callbacks,\n",
    "#                           validation_data=(xValid, xValid)\n",
    "#                          )\n",
    "# vae.encoder.save('./encoder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
