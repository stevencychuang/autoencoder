{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on 2018年10月18日\n",
    "\n",
    "@author: STEVEN.CY.CHUANG\n",
    "\"\"\"\n",
    "\n",
    "from time import time\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.metrics import binary_accuracy\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append(\"../\")\n",
    "from util.util import *\n",
    "from util import importNotebook\n",
    "from module.autoencoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "class TestAE(unittest.TestCase):\n",
    "    \n",
    "    num_epochs = 10\n",
    "    size_batch = 512\n",
    "    size_kernel = 3\n",
    "    lay_den_enc = [32, 8]\n",
    "    name_optim = \"adam\"\n",
    "    path_temp_best = \"../model/temp/\"\n",
    "    patience = 3\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.\n",
    "    x_test = x_test.astype(\"float32\") / 255.\n",
    "    num_train = len(x_train)\n",
    "    num_test = len(x_test)\n",
    "    size_digit = x_train.shape[1:]\n",
    "\n",
    "    dim_input = np.prod(x_train.shape[1:])\n",
    "    x_train = x_train.reshape((num_train, dim_input))\n",
    "    x_test = x_test.reshape((num_test, dim_input))\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        print(\"Test for AE:\")\n",
    "        print(\"Test for init:\")\n",
    "        ae = AE(self.dim_input, lay_den_enc=self.lay_den_enc)\n",
    "        ae.encoder.summary()\n",
    "        ae.decoder.summary()\n",
    "        ae.autoencoder.summary()\n",
    "        self.ae = ae\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_specific_decode(self):\n",
    "        print(\"Test for specificdecode:\")\n",
    "        ae = AE(self.dim_input, lay_den_enc=self.lay_den_enc, lay_den_dec=[1, 4, 16])\n",
    "        ae.fit(self.x_train, self.x_test, \n",
    "               num_epochs=5,\n",
    "               patience=1,\n",
    "               size_batch=1024,\n",
    "               metrics=[\"binary_accuracy\"],\n",
    "               path_temp_best=self.path_temp_best)\n",
    "        ae.encoder.summary()\n",
    "        ae.decoder.summary()\n",
    "        ae.autoencoder.summary()\n",
    "        print(\"\\r\\n\")\n",
    "\n",
    "        \n",
    "    def test_fit(self):\n",
    "        print(\"Test for fitting:\")\n",
    "        history, time_train = self.ae.fit(self.x_train, self.x_test, \n",
    "                                         num_epochs=self.num_epochs,\n",
    "                                         size_batch=self.size_batch,\n",
    "                                         path_temp_best=self.path_temp_best\n",
    "                                        )\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        print(\"Test for checking best fit:\")\n",
    "        history, time_train = self.ae.fit(self.x_train, self.x_test, \n",
    "                                         num_epochs=20,\n",
    "                                         patience=1,\n",
    "                                         size_batch=self.size_batch,\n",
    "                                         metrics=[\"binary_accuracy\"],\n",
    "                                         path_temp_best=self.path_temp_best\n",
    "                                        )\n",
    "        # print the binary accuracy of testing dataset for verifying best model\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.x_test, self.ae.autoencoder.predict(self.x_test))).mean())\n",
    "        print(\"\\r\\n\")\n",
    "    \n",
    "    \n",
    "    def test_fit_check_verbose(self):\n",
    "        print(\"Test for verbose:\")\n",
    "        history, time_train = self.ae.fit(self.x_train, self.x_test, \n",
    "                                         num_epochs=self.num_epochs,\n",
    "                                         size_batch=self.size_batch,\n",
    "                                         path_temp_best=self.path_temp_best,\n",
    "                                         verb=0\n",
    "                                        )\n",
    "        history, time_train = self.ae.fit(self.x_train, self.x_test, \n",
    "                                         num_epochs=self.num_epochs,\n",
    "                                         size_batch=self.size_batch,\n",
    "                                         path_temp_best=self.path_temp_best,\n",
    "                                         verb=1\n",
    "                                        )\n",
    "        history, time_train = self.ae.fit(self.x_train, self.x_test, \n",
    "                                         num_epochs=self.num_epochs,\n",
    "                                         size_batch=self.size_batch,\n",
    "                                         path_temp_best=self.path_temp_best,\n",
    "                                         verb=2\n",
    "                                        )\n",
    "        print(\"\\r\\n\")\n",
    "    \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        print(\"Test for saving seperately:\")\n",
    "        self.ae.encoder.save(\"../model/test/AE/encoder.h5\")\n",
    "        self.ae.decoder.save(\"../model/test/AE/decoder.h5\")\n",
    "        print(\"\\r\\n\")\n",
    "\n",
    "        \n",
    "    def test_save(self):\n",
    "        print(\"Test for saving:\")\n",
    "        self.ae.save(\"../model/test/AE/ae\")\n",
    "        print(\"\\r\\n\")\n",
    "                \n",
    "            \n",
    "    def test_load_seperate(self):\n",
    "        print(\"Test for loading seperately:\")\n",
    "        encoder = keras.models.load_model(\"../model/test/AE/encoder.h5\")\n",
    "        decoder = keras.models.load_model(\"../model/test/AE/decoder.h5\")\n",
    "#         autoencoder = keras.models.load_model(\"./temp/autoencoder.h5\", custom_objects={\"lossae\": lossae})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.x_test)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "#         decodeTest2 = autoencoder.predict(self.x_test)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "#         Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.x_test, decodeTest, sizeDigit=self.size_digit)\n",
    "        err = compReconst(self.x_test, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        print(\"Test for loading:\")\n",
    "        encoder, decoder, autoencoder = load(\"../model/test/AE/ae\")\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.x_test)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        decodeTest2 = autoencoder.predict(self.x_test)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.x_test, decodeTest, sizeDigit=self.size_digit)\n",
    "        err = compReconst(self.x_test, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        print(\"Test for prediction:\")\n",
    "        # Set the initialization\n",
    "        x_test = self.x_test\n",
    "        y_test = self.y_test\n",
    "        size_digit = self.size_digit\n",
    "        ae = self.ae\n",
    "        encoder = ae.encoder\n",
    "        decoder = ae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encode_test = encoder.predict(x_test)\n",
    "        decode_test = decoder.predict(encode_test)\n",
    "        meanEncTest = np.mean(encode_test, axis=0)\n",
    "        stdEncTest = np.std(encode_test, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(x_test, decode_test, sizeDigit=size_digit)\n",
    "        err = compReconst(x_test, decode_test)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encode_test, y_test, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encode_test, y_test)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, size_digit, xlim, ylim)\n",
    "        print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class TestConvAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 5\n",
    "    sizeBatch = 512\n",
    "    layDenEnc = [8]\n",
    "    layConvEnc = [4, 16]\n",
    "    nameOptim = \"adam\"\n",
    "    pathTempBest = \"../model/temp/\"\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype(\"float32\") / 255.\n",
    "    xTest = xTest.astype(\"float32\") / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "    dimInput = [*sizeDigit, 1]\n",
    "    xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "    xTest = xTest.reshape((numTest, *dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        print(\"Test for ConvAE:\")\n",
    "        print(\"Test for init:\")\n",
    "        convAE = ConvAE(self.dimInput, lay_den_enc=self.layDenEnc, lay_conv_enc=self.layConvEnc)\n",
    "        convAE.encoder.summary()\n",
    "        convAE.decoder.summary()\n",
    "        convAE.autoencoder.summary()\n",
    "        self.convAE = convAE\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_specific_decode(self):\n",
    "        print(\"Test for specificdecode:\")\n",
    "        convAE = ConvAE(self.dimInput, lay_den_enc=self.layDenEnc, lay_den_dec=[1, 4, 16])\n",
    "        convAE.fit(self.xTrain, self.xTest, \n",
    "                   num_epochs=5,\n",
    "                   patience=1,\n",
    "                   size_batch=1024,\n",
    "                   metrics=[\"binary_accuracy\"],\n",
    "                   path_temp_best=self.pathTempBest)\n",
    "        convAE.encoder.summary()\n",
    "        convAE.decoder.summary()\n",
    "        convAE.autoencoder.summary()\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "\n",
    "    def test_fit(self):\n",
    "        print(\"Test for fitting:\")\n",
    "        history, timeTrain = self.convAE.fit(self.xTrain, self.xTest, \n",
    "                                             num_epochs=self.numEpochs,\n",
    "                                             size_batch=self.sizeBatch,\n",
    "                                             path_temp_best=self.pathTempBest)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        print(\"Test for checking best fit:\")\n",
    "        history, timeTrain = self.convAE.fit(self.xTrain, self.xTest, \n",
    "                                             num_epochs=20,\n",
    "                                             patience=1,\n",
    "                                             size_batch=self.sizeBatch,\n",
    "                                             metrics=[\"binary_accuracy\"],\n",
    "                                             path_temp_best=self.pathTempBest)\n",
    "        \n",
    "        # print the binary accuracy of testing dataset for verifying best model\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.xTest, self.convAE.autoencoder.predict(self.xTest))).mean())\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        print(\"Test for saving seperately:\")\n",
    "        self.convAE.encoder.save(\"../model/test/ConvAE/encoder.h5\")\n",
    "        self.convAE.decoder.save(\"../model/test/ConvAE/decoder.h5\")\n",
    "        print(\"\\r\\n\")\n",
    "\n",
    "        \n",
    "    def test_save(self):\n",
    "        print(\"Test for saving:\")\n",
    "        self.convAE.save(\"../model/test/ConvAE/convAE\")\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_load_seperate(self):\n",
    "        print(\"Test for loading seperately:\")\n",
    "        encoder = keras.models.load_model(\"../model/test/ConvAE/encoder.h5\")\n",
    "        decoder = keras.models.load_model(\"../model/test/ConvAE/decoder.h5\")\n",
    "#         autoencoder = keras.models.load_model(\"./temp/autoencoder.h5\", custom_objects={\"lossae\": lossae})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "#         decodeTest2 = autoencoder.predict(self.xTest)\n",
    "#         Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        print(\"Test for loading:\")\n",
    "        encoder, decoder, autoencoder = load(\"../model/test/ConvAE/convAE\")\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        print(\"Test for prediction:\")\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        ae = self.convAE\n",
    "        encoder = ae.encoder\n",
    "        decoder = ae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)\n",
    "        print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "class TestVAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 10\n",
    "    sizeBatch = 512\n",
    "    sizeKernel = 3\n",
    "    layDenEnc = [32, 8]\n",
    "    ratRecon = 1\n",
    "    nameOptim = \"adam\"\n",
    "    pathTempBest = \"../model/temp/\"\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype(\"float32\") / 255.\n",
    "    xTest = xTest.astype(\"float32\") / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "    dimInput = np.prod(xTrain.shape[1:])\n",
    "    xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "    xTest = xTest.reshape((numTest, dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        print(\"Test for VAE:\")\n",
    "        print(\"Test for init:\")\n",
    "        vae = VAE(self.dimInput, lay_den_enc=self.layDenEnc, rat_recon=self.ratRecon)\n",
    "        vae.encoder.summary()\n",
    "        vae.decoder.summary()\n",
    "        vae.autoencoder.summary()\n",
    "        self.vae = vae\n",
    "        print(\"\\r\\n\")\n",
    "\n",
    "        \n",
    "    def test_fit(self):\n",
    "        print(\"Test for fitting:\")\n",
    "        history, timeTrain = self.vae.fit(self.xTrain, self.xTest, \n",
    "                                          num_epochs=self.numEpochs,\n",
    "                                          size_batch=self.sizeBatch,\n",
    "                                          path_temp_best=self.pathTempBest)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_fit_check_best(self):\n",
    "        print(\"Test for checking best fit:\")\n",
    "        history, timeTrain = self.vae.fit(self.xTrain, self.xTest, \n",
    "                                          num_epochs=20,\n",
    "                                          patience = 1,\n",
    "                                          size_batch=self.sizeBatch,\n",
    "                                          metrics=[\"binary_accuracy\"],\n",
    "                                          path_temp_best=self.pathTempBest)\n",
    "        print(tf.keras.backend.eval(binary_accuracy(self.xTest, self.vae.autoencoder.predict(self.xTest))).mean())\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "    \n",
    "    def test_save_seperate(self):\n",
    "        print(\"Test for saving seperately:\")\n",
    "        self.vae.encoder.save(\"../model/test/VAE/encoder.h5\")\n",
    "        self.vae.decoder.save(\"../model/test/VAE/decoder.h5\")\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_save(self):\n",
    "        print(\"Test for saving:\")\n",
    "        self.vae.save(\"../model/test/VAE/vae\")\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_load_seperate(self):\n",
    "        print(\"Test for loading seperately:\")\n",
    "        encoder = keras.models.load_model(\"../model/test/VAE/encoder.h5\")\n",
    "        decoder = keras.models.load_model(\"../model/test/VAE/decoder.h5\")\n",
    "#         autoencoder = keras.models.load_model(\"./temp/autoencoder.h5\", custom_objects={\"lossVAE\": lossVAE})\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "#         autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        print(\"Test for loading:\")\n",
    "        encoder, decoder, autoencoder = load(\"../model/test/VAE/vae\")\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "    \n",
    "    def test_prediction(self):\n",
    "        print(\"Test for prediction:\")\n",
    "        # Set the initialization\n",
    "        xTrain = self.xTrain\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        vae = self.vae\n",
    "        encoder = vae.encoder\n",
    "        decoder = vae.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)    \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)\n",
    "        print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class TestConvVAE(unittest.TestCase):\n",
    "    \n",
    "    numEpochs = 5\n",
    "    sizeBatch = 512\n",
    "    sizeKernel = 3\n",
    "    layDenEnc = [4]\n",
    "    layConvEnc = [4]\n",
    "    ratRecon = 1\n",
    "    nameOptim = \"adam\"\n",
    "    pathTempBest = \"../model/temp/\"\n",
    "    patience = 3\n",
    "    \n",
    "    (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "    xTrain = xTrain.astype(\"float32\") / 255.\n",
    "    xTest = xTest.astype(\"float32\") / 255.\n",
    "    numTrain = len(xTrain)\n",
    "    numTest = len(xTest)\n",
    "    sizeDigit = xTrain.shape[1:]\n",
    "    dimInput = [*sizeDigit, 1]\n",
    "    xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "    xTest = xTest.reshape((numTest, *dimInput))\n",
    "    print(xTrain.shape)\n",
    "    print(xTest.shape)\n",
    "    \n",
    "    def test_init(self):\n",
    "        print(\"Test for ConvVAE:\")\n",
    "        print(\"Test for init:\")\n",
    "        convVAE = ConvVAE(self.dimInput, lay_den_enc=self.layDenEnc, lay_conv_enc=self.layConvEnc, rat_recon=self.ratRecon)\n",
    "        convVAE.encoder.summary()\n",
    "        convVAE.decoder.summary()\n",
    "        convVAE.autoencoder.summary()\n",
    "        self.convVAE = convVAE\n",
    "        print(\"\\r\\n\")\n",
    "\n",
    "    def test_fit(self):\n",
    "        print(\"Test for fitting:\")\n",
    "        history, timeTrain = self.convVAE.fit(self.xTrain, self.xTest, \n",
    "                                              num_epochs=self.numEpochs,\n",
    "                                              size_batch=self.sizeBatch,\n",
    "                                              verb=1,\n",
    "                                              path_temp_best=self.pathTempBest)\n",
    "        print(\"\\r\\n\")\n",
    "\n",
    "        \n",
    "    def test_save(self):\n",
    "        print(\"Test for saving:\")\n",
    "        self.convVAE.save(\"../model/test/ConvVAE/convVAE\")\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_load(self):\n",
    "        print(\"Test for loading:\")\n",
    "        encoder, decoder, autoencoder = load(\"../model/test/ConvVAE/convVAE\")\n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "        autoencoder.summary()\n",
    "        encodeTest = encoder.predict(self.xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(self.xTest, decodeTest, sizeDigit=self.sizeDigit)\n",
    "        err = compReconst(self.xTest, decodeTest)\n",
    "        print(err)\n",
    "        print(\"\\r\\n\")\n",
    "        \n",
    "        \n",
    "    def test_prediction(self):\n",
    "        print(\"Test for prediction:\")\n",
    "        # Set the initialization\n",
    "        xTest = self.xTest\n",
    "        yTest = self.yTest\n",
    "        sizeDigit = self.sizeDigit\n",
    "        convVAE = self.convVAE\n",
    "        encoder = convVAE.encoder\n",
    "        decoder = convVAE.decoder\n",
    "        \n",
    "        # Get encoded and decoded values\n",
    "        encodeTest = encoder.predict(xTest)\n",
    "        decodeTest = decoder.predict(encodeTest)\n",
    "        meanEncTest = np.mean(encodeTest, axis=0)\n",
    "        stdEncTest = np.std(encodeTest, axis=0)\n",
    "        \n",
    "        # Plot the comparison of original and reconstructed pictures, and calculate the errors\n",
    "        plotCompDecode(xTest, decodeTest, sizeDigit=sizeDigit)\n",
    "        err = compReconst(xTest, decodeTest)\n",
    "        print(err)\n",
    "        \n",
    "        # Plot the scatter of the encoding space\n",
    "        xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "        ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "        plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "        scoreSilh = silhouette_score(encodeTest, yTest)  \n",
    "        \n",
    "        # Plot the decoding results from the encoding scatter\n",
    "        plotScatterDecode(decoder, sizeDigit, xlim, ylim)\n",
    "        print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for AE:\n",
      "Test for init:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 25,562\n",
      "Trainable params: 25,482\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 26,344\n",
      "Trainable params: 26,264\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 25562     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               26344     \n",
      "=================================================================\n",
      "Total params: 51,906\n",
      "Trainable params: 51,746\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Test for fitting:\n",
      "\n",
      "\n",
      "Test for verbose:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    testAE = TestAE()\n",
    "    testAE.test_init()\n",
    "    testAE.test_fit()\n",
    "#     testAE.test_fit_check_best()\n",
    "    testAE.test_fit_check_verbose()\n",
    "    testAE.test_prediction()\n",
    "    testAE.test_save()\n",
    "    testAE.test_load()\n",
    "    testAE.test_specific_decode()\n",
    "     \n",
    "    testConvAE = TestConvAE()\n",
    "    testConvAE.test_init()\n",
    "    testConvAE.test_fit()\n",
    "#     testConvAE.test_fit_check_best()\n",
    "    testConvAE.test_prediction()\n",
    "    testConvAE.test_save()\n",
    "    testConvAE.test_load()\n",
    "    testConvAE.test_specific_decode()\n",
    "    \n",
    "    testVAE = TestVAE()\n",
    "    testVAE.test_init()\n",
    "    testVAE.test_fit()\n",
    "#     testVAE.test_fit_check_best()\n",
    "    testVAE.test_prediction()\n",
    "    testVAE.test_save()\n",
    "    testVAE.test_load()\n",
    "\n",
    "    testConv = TestConvVAE()\n",
    "    testConv.test_init()\n",
    "    testConv.test_fit()\n",
    "    testConv.test_prediction()\n",
    "    testConv.test_save()\n",
    "    testConv.test_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# import numpy as np\n",
    "# numEpochs = 2\n",
    "# sizeBatch = 128\n",
    "# sizeKernel = 3\n",
    "# layerDense = [16, 2]\n",
    "# ratRecon = 1\n",
    "# nameOptim = 'adam'\n",
    "# modelPath = '../model/temp/'\n",
    "# patience = 3\n",
    "# stdEps = 1.0\n",
    "\n",
    "# (xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "# xTrain = xTrain.astype('float32') / 255.\n",
    "# xTest = xTest.astype('float32') / 255.\n",
    "# numTrain = len(xTrain)\n",
    "# numTest = len(xTest)\n",
    "# sizeDigit = xTrain.shape[1:]\n",
    "\n",
    "# dimInput = np.prod(xTrain.shape[1:])\n",
    "# xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "# xTest = xTest.reshape((numTest, dimInput))\n",
    "# print(xTrain.shape)\n",
    "# print(xTest.shape)\n",
    "\n",
    "\n",
    "# layerDense=[64, 2] \n",
    "# actDense='relu'\n",
    "# ratRecon=0.998\n",
    "# dimEncode = layerDense[-1]\n",
    "\n",
    "# inputs = Input(shape=(dimInput,)) \n",
    "# x = inputs\n",
    "\n",
    "# # Stack of Dense layers\n",
    "# for numFilt in layerDense[:-1]:\n",
    "#     x = Dense(numFilt, activation=actDense)(x)\n",
    "# zMean = Dense(dimEncode)(x)\n",
    "# zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "# def sampling(args):\n",
    "#     zMean, zSigmaLog = args\n",
    "#     epsilon = K.random_normal(shape=(K.shape(zMean)[0], K.shape(zMean)[1]),\n",
    "#                               mean=0., stddev=stdEps)\n",
    "#     return zMean + K.exp(zSigmaLog) * epsilon  \n",
    "    \n",
    "# # Construct the latent as the output and build the encorder pipeline\n",
    "# z = Lambda(sampling)([zMean, zSigmaLog])\n",
    "# encoder = Model(inputs, z, name='encoder')\n",
    "\n",
    "# # Build the Decoder Model\n",
    "# inputLatent = Input(shape=(dimEncode,), name='decoder_input')\n",
    "# x = inputLatent\n",
    "# for numFilt in layerDense[-2::-1]:\n",
    "#     x = Dense(numFilt, activation=actDense)(x)\n",
    "\n",
    "# # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "# outputs = Dense(dimInput, activation='sigmoid', name='decoder_output')(x)\n",
    "# decoder = Model(inputLatent, outputs, name='decoder')\n",
    "\n",
    "# autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "\n",
    "# def lossVAE(tensorInput, tensorDecode):\n",
    "#     zMean = zMean\n",
    "#     zSigmaLog = zSigmaLog\n",
    "#     ratRecon = ratRecon\n",
    "\n",
    "#     lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "# #         lossRecon =  metrics.mean_squared_error(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "#     lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "#     return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "\n",
    "# autoencoder.compile(optimizer=nameOptim, loss=lossVAE)\n",
    "\n",
    "# history = autoencoder.fit(xTrain, xTrain,\n",
    "#                           epochs=numEpochs,\n",
    "#                           batch_size=sizeBatch, shuffle=True,\n",
    "#                           callbacks=callbacks,\n",
    "#                           validation_data=(xValid, xValid)\n",
    "#                          )\n",
    "# vae.encoder.save('./encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
