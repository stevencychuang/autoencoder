{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All rights can reffer to the LICENSE.md.\n",
    "\n",
    "Created on July 19, 2018.\n",
    "\n",
    "This module provides the several classes of autoencoder series.\n",
    "The use could simply use these API without defining the structure by oneself.\n",
    "\n",
    "@author: steven.cy.chuang\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, model_from_json\n",
    "from keras import backend as K\n",
    "from keras.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path_folder):\n",
    "    \"\"\"\n",
    "    The method is to save the models of autoencoders as several hdf5 files in a given path of the folder.\n",
    "    Args:\n",
    "        path_folder (string): the given path of the folder where contains encoder, decoder, and autoencoder\n",
    "    Returns:\n",
    "        encoder (keras model): the model of encoder\n",
    "        decoder (keras model): the model of decoder\n",
    "        autoencoder (keras model) : the model of autoencoder. autoencoder.predict(x) is equivalent to decoder.predict(encoder.predict(x))\n",
    "    \"\"\"\n",
    "    encoder = keras.models.load_model(path_folder+\"/encoder.h5\")\n",
    "    decoder = keras.models.load_model(path_folder+\"/decoder.h5\")\n",
    "\n",
    "    with open(path_folder+\"/configAutoencoder.json\", \"r\") as jsonFile:                              \n",
    "        jsonConfig = jsonFile.readlines()[0]\n",
    "    autoencoder = model_from_json(jsonConfig)\n",
    "    autoencoder.load_weights(path_folder+\"/weightAutoencoder.h5\")\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE():\n",
    "    def __init__(self, \n",
    "                 dim_input,  dim_latent=2,\n",
    "                 lay_den_enc=[64], lay_den_dec=None, act_dense=\"leaky_relu\", dropout_dense=0.5,\n",
    "                 batch_norm=True):\n",
    "        \"\"\"\n",
    "        The basic properties and pipeline will be defined in the initialization.\n",
    "        It should be noted that lay_den_enc defines the first half(encoder) of network. \n",
    "        The decoder will be reflected structure.\n",
    "        For example, [64, 16] and plus the latent 2 means that the nodes of encoder is [64, 16, 2]. \n",
    "        Meanwhile decoder will be [2, 16, 64]. \n",
    "        Args:\n",
    "            dim_input (int): the number of input dimension. All features are flatten as a vector.\n",
    "            dim_latent (in): the number of the dimension for latent feature. Default is 2.\n",
    "            lay_den_enc (list[int]): the numbers of each dense layer of encoder. Default is [64].\n",
    "            lay_den_dec (list[int]): the numbers of each dense layer of decoder. Default is None that means reverse order of encoder.\n",
    "            act_dense (string): the activation function. Default is \"leaky_relu\".\n",
    "            dropout_dense (float): the dropout layer. Default is 0.5.\n",
    "            batch_norm (bool): determine if apply batch normalization after dense layers. Default is True and epsilon=1e-5.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize some setting \n",
    "        self._dim_input = dim_input # all features are flatten as a vector\n",
    "        self._inputs = Input(shape=(dim_input,)) \n",
    "        self._dim_latent = dim_latent\n",
    "        if lay_den_dec is None:\n",
    "            lay_den_dec = lay_den_enc[::-1]\n",
    "        \n",
    "        self._encoding(lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        self._decoding(lay_den_dec, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)), name=\"autoencoder\")\n",
    "\n",
    "        \n",
    "    def _stack_dense(self, x, lay_dense, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\"\n",
    "        Stacking for dense layers whether encoder or decoder.\n",
    "        The sequence is:\n",
    "            Dense layers\n",
    "            Batch normalization\n",
    "            Activation function\n",
    "            Dropout\n",
    "        \"\"\"\n",
    "        for num_node in lay_dense:\n",
    "            x = Dense(num_node)(x)\n",
    "            if batch_norm :\n",
    "                x = BatchNormalization(epsilon=1e-5)(x)\n",
    "            if act_dense == \"leaky_relu\":\n",
    "                x = LeakyReLU()(x)\n",
    "            else:\n",
    "                x = Activation(act_dense)(x)\n",
    "            if dropout_dense > 0:\n",
    "                x = Dropout(0.5)(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def _encoding(self, lay_den_enc, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \n",
    "        The flow of encoding\n",
    "        \"\"\"\n",
    "        x = self._inputs\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        x = self._stack_dense(x, lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Dense(self._dim_latent)(x)\n",
    "        self.encoder = Model(self._inputs, z, name=\"encoder\")\n",
    "\n",
    "        \n",
    "    def _decoding(self, lay_den_dec, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \n",
    "        The flow of decoding\n",
    "        \"\"\"\n",
    "        # Build the Decoder Model\n",
    "        input_latent = Input(shape=(self._dim_latent,), name=\"decoder_input\")\n",
    "        x = input_latent\n",
    "        \n",
    "        # Stack of Dense layers\n",
    "        x = self._stack_dense(x, lay_den_dec, batch_norm, act_dense, dropout_dense)\n",
    "            \n",
    "        # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "        outputs = Dense(self._dim_input, activation=\"sigmoid\", name=\"decoder_output\")(x)\n",
    "        self.decoder = Model(input_latent, outputs, name=\"decoder\")\n",
    "\n",
    "        \n",
    "    def fit(self,\n",
    "            x_train, x_valid,\n",
    "            num_epochs=50, size_batch=32, name_optim=\"adam\", metrics=None, verb=1,\n",
    "            path_temp_best=None, patience=3):\n",
    "        \"\"\"\n",
    "        The method is for training process. \n",
    "        The users can call this method easily just putting training and validation datasets.\n",
    "        The dimension of dataset is determined by [#instance, *dimInput].\n",
    "        For example, dimInput is flatten as a number and the dimension of dataset is [#instance, #feature]\n",
    "        If dimInput is a list to represent [width, height, channels], the dimension of dataset is [#instance, width, height, channels]\n",
    "        Args:\n",
    "            x_train (numpy ndarray): the training dataset.\n",
    "            x_valid (numpy ndarray): the validation dataset.\n",
    "            num_epochs (int): the maximal epochs for training. Default is 50.\n",
    "            size_batch (int): the batch size. Default is 32.\n",
    "            name_optim (string): the method for optimization. Default is adam.\n",
    "            metrics (list(string or keras metrics)): the usage is the same with keras metrics for compile.\n",
    "            verb(int): verbose; it is applied for both of fit and callback. The setting is similar to keras.\n",
    "            path_temp_best (string): the temperory path of the best model for early-stop. Default None means without early-stop. \n",
    "            patience (int): the times of epochs to allow further trying if current loss is not better than the best. \n",
    "        Returns:\n",
    "            history (keras.callbacks.History): the learning curving for the training process\n",
    "            time_train (float): the consuming time of the training \n",
    "        \"\"\"\n",
    "        self.autoencoder.compile(optimizer=name_optim, loss=\"binary_crossentropy\", metrics=metrics)\n",
    "\n",
    "        if path_temp_best is None:\n",
    "            callbacks = None\n",
    "        else:\n",
    "            if not os.path.exists(path_temp_best): # make sure the folder exists\n",
    "                os.makedirs(path_temp_best)\n",
    "            \n",
    "            name_temp = \"AutoEncoder\" + str(time()) # use timestamp as unique name\n",
    "            cb_es = EarlyStopping(monitor=\"val_loss\", patience=patience, verbose=verb, mode=\"auto\")\n",
    "            chkpt = path_temp_best + \"/\" + name_temp + \".hdf5\"\n",
    "            cb_cp = ModelCheckpoint(filepath = chkpt, monitor=\"val_loss\", verbose=verb, save_best_only=True, mode=\"auto\")\n",
    "            callbacks = [cb_es, cb_cp]\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        tic = time()\n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                                       epochs=num_epochs,\n",
    "                                       batch_size=size_batch, shuffle=True,\n",
    "                                       callbacks=callbacks,\n",
    "                                       validation_data=(x_valid, x_valid),\n",
    "                                       verbose=verb)\n",
    "        time_train = time() - tic\n",
    "        \n",
    "        # Assure the models are resuming from the best models\n",
    "        if path_temp_best is not None:\n",
    "            self.autoencoder = keras.models.load_model(chkpt)\n",
    "            self.encoder = self.autoencoder.layers[1]\n",
    "            self.decoder = self.autoencoder.layers[2]\n",
    "        \n",
    "        return history, time_train\n",
    "    \n",
    "        \n",
    "    def save(self, path_folder):\n",
    "        \"\"\"\n",
    "        Deprecated! Because the availability for saving/loading model is limited.\n",
    "        The method is to save the models of autoencoders as several hdf5 files in a given path of the folder.\n",
    "        Args:\n",
    "            path_folder (string): the given path of the folder where contains encoder, decoder, and autoencoder\n",
    "        Returns:\n",
    "            msg (string): the message for the saving process\n",
    "        \"\"\"\n",
    "        # Create the message for saving model\n",
    "        msg = \"\"\n",
    "        if os.path.exists(path_folder):\n",
    "            msg += \"There is a existing folder.\\r\\n\"\n",
    "        else:\n",
    "            os.makedirs(path_folder)\n",
    "            msg += \"Create a new folder.\\r\\n\"\n",
    "        \n",
    "        # Save the models of encoder and decoder with save()\n",
    "        self.encoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\") # avoid saving warning\n",
    "        self.decoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\") # avoid saving warning\n",
    "        self.encoder.save(path_folder+\"/encoder.h5\")\n",
    "        self.decoder.save(path_folder+\"/decoder.h5\")\n",
    "        \n",
    "        # Save the model of autoencoder with json and save_weights(). \n",
    "        # Because autoencoder contains special loss function and sample function.\n",
    "        self.autoencoder.save_weights(path_folder+\"/weightAutoencoder.h5\")\n",
    "        with open(path_folder+\"/configAutoencoder.json\", \"w\") as json_file:\n",
    "            json_file.write(self.autoencoder.to_json())\n",
    "        msg += \"successful.\\r\\n\"\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(AE):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dim_input, dim_latent=2,\n",
    "                 lay_conv_enc=[8, 32], lay_conv_dec=None, size_kernel=3, strides=2, act_conv=\"leaky_relu\", padding=\"same\",\n",
    "                 lay_den_enc=[64], lay_den_dec=None, act_dense=\"leaky_relu\", dropout_dense=0.5,\n",
    "                 batch_norm = True):\n",
    "        \"\"\"\n",
    "        The basic properties and pipeline will be defined in the initialization.\n",
    "        The dimension of input should be a form of a picture presented by a list [width, height, channels].\n",
    "        It should be noted that lay_den_enc defines the first half(encoder) of network. \n",
    "        The decoder will be reflected structure.\n",
    "        For example, [64, 16] and plus the latent 2 means that the nodes of encoder is [64, 16, 2]. \n",
    "        Meanwhile decoder will be [2, 16, 64]. \n",
    "        It is similar for lay_conv_enc but decoder is not purely symmetric for convolution layers for this version.\n",
    "        Args:\n",
    "            dim_input (list[int]): the dimension of input. E.g. [32, 28, 3] means 32 by 28 RGB pixels.\n",
    "            dim_latent (in): the number of the dimension for latent feature. Default is 2.\n",
    "            lay_conv_enc (list[int]): the numbers of each convolution layer of encoder. Default is [8, 32].\n",
    "            lay_conv_dec (list[int]): the numbers of each convolution layer of decoder. Default is None that means reverse order of encoder.\n",
    "            size_kernel (int): the size of filter kernel. Default 3 means 3 by 3.\n",
    "            strides (int): the stride for convolution. Default is 2.\n",
    "            act_conv (string): the activation function of each convolution layer. Default is \"leaky_relu\".\n",
    "            padding (string): the padding method for convolution. Default is \"same\".\n",
    "            lay_den_enc (list[int]): the numbers of each dense layer of encoder. Default is [64].\n",
    "            lay_den_dec (list[int]): the numbers of each dense layer of decoder. Default is None that means reverse order of encoder.\n",
    "            act_dense (string): the activation function of each dense layer. Default is \"leaky_relu\".\n",
    "            dropout_dense (float): the dropout layer. Default is 0.5.\n",
    "            batch_norm (bool): determine if apply batch normalization after dense/conv layers. Default is True and epsilon=1e-5.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize some setting \n",
    "        self._dim_input = dim_input # dim_input is (width, height, channels)\n",
    "        self._inputs = Input(shape=(dim_input)) \n",
    "        self._dim_latent = dim_latent\n",
    "        if lay_conv_dec is None:\n",
    "            lay_conv_dec = lay_conv_enc[::-1]\n",
    "        if lay_den_dec is None:\n",
    "            lay_den_dec = lay_den_enc[::-1]\n",
    "\n",
    "        print(lay_den_dec)\n",
    "            \n",
    "        self._encoding(lay_conv_enc, size_kernel, strides, act_conv, padding,\n",
    "                       lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        self._decoding(lay_conv_dec, size_kernel, strides, act_conv, padding,\n",
    "                       lay_den_dec, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)), name=\"autoencoder\")\n",
    "\n",
    "        \n",
    "    def _stack_conv(self, x, \n",
    "                   lay_conv_enc, size_kernel, strides, padding,\n",
    "                   batch_norm, act_conv, is_trans=False):\n",
    "        \"\"\"\n",
    "        Stacking for convolutional layers whether encoder or decoder.\n",
    "        Transpose convolutional layers are applied for decoder.\n",
    "        The sequence is:\n",
    "            Convolution(Transpose) layers\n",
    "            Batch normalization\n",
    "            Activation function\n",
    "        \"\"\"\n",
    "        for filters in lay_conv_enc:\n",
    "            if is_trans:\n",
    "                x = Conv2DTranspose(filters=filters,\n",
    "                                    kernel_size=size_kernel,\n",
    "                                    strides=strides,\n",
    "                                    padding=padding)(x)\n",
    "            else:\n",
    "                x = Conv2D(filters=filters,\n",
    "                           kernel_size=size_kernel,\n",
    "                           strides=strides,\n",
    "                           padding=padding)(x)\n",
    "            if batch_norm :\n",
    "                x = BatchNormalization(epsilon=1e-5)(x)\n",
    "            if act_conv == \"leaky_relu\":\n",
    "                x = LeakyReLU()(x)\n",
    "            else:\n",
    "                x = Activation(act_conv)(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def _encoding(self,\n",
    "                  lay_conv_enc, size_kernel, strides, act_conv, padding,\n",
    "                  lay_den_enc, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \n",
    "        The flow of encoding\n",
    "        \"\"\"\n",
    "        x = self._inputs\n",
    "        \n",
    "        # Stack of Conv2D layers\n",
    "        x = self._stack_conv(x, \n",
    "                            lay_conv_enc, size_kernel, strides, padding,\n",
    "                            batch_norm, act_conv)\n",
    "\n",
    "        # Shape info needed to build Decoder Model\n",
    "        self._shape_last_conv = K.int_shape(x)\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        x = Flatten()(x)\n",
    "        x = self._stack_dense(x, lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Dense(self._dim_latent)(x)\n",
    "        self.encoder = Model(self._inputs, z, name=\"encoder\")\n",
    "\n",
    "        \n",
    "    def _decoding(self,\n",
    "                  lay_conv_dec, size_kernel, strides, act_conv, padding,\n",
    "                  lay_den_dec, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \n",
    "        The flow of decoding\n",
    "        \"\"\"\n",
    "        shape_last_conv = self._shape_last_conv\n",
    "        # Build the Decoder Model\n",
    "        input_latent = Input(shape=(self._dim_latent,), name=\"decoder_input\")\n",
    "        x = input_latent\n",
    "        \n",
    "        # Stack of Dense layers\n",
    "        x = self._stack_dense(x, lay_den_dec, batch_norm, act_dense, dropout_dense)\n",
    "        x = Dense(shape_last_conv[1] * shape_last_conv[2] * shape_last_conv[3])(x)\n",
    "        x = Reshape((shape_last_conv[1], shape_last_conv[2], shape_last_conv[3]))(x)\n",
    "\n",
    "        # Stack of Transposed Conv2D layers\n",
    "        x = self._stack_conv(x, \n",
    "                            lay_conv_dec, size_kernel, strides, padding,\n",
    "                            batch_norm, act_conv, is_trans=True)\n",
    "\n",
    "        # Build the Conv2DTranspose layer for the pixel dimension\n",
    "        x = Conv2DTranspose(filters=self._dim_input[-1],\n",
    "                            kernel_size=size_kernel,\n",
    "#                             strides=strides,\n",
    "                            padding=padding)(x)\n",
    "\n",
    "        # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "        outputs = Activation(\"sigmoid\", name=\"decoder_output\")(x)\n",
    "        self.decoder = Model(input_latent, outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(AE):\n",
    "    _std_eps = 1.0\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dim_input, dim_latent=2,\n",
    "                 lay_den_enc=[64], lay_den_dec=None, act_dense=\"leaky_relu\", dropout_dense=0.5,\n",
    "                 batch_norm=True,\n",
    "                 rat_recon=0.998):\n",
    "        \"\"\"\n",
    "        The basic properties and pipeline will be defined in the initialization.\n",
    "        It should be noted that lay_den_enc defines the first half(encoder) of network. \n",
    "        The decoder will be reflected structure.\n",
    "        For example, [64, 16] and plus the latent 2 means that the nodes of encoder is [64, 16, 2]. \n",
    "        Meanwhile decoder will be [2, 16, 64].  \n",
    "        There is another parameter should noted that rat_recon=0.5 doesn't mean the effect is half.\n",
    "        Because KL loss and reconstruction loss are not the same scale.\n",
    "        Args:\n",
    "            dim_input (int): the number of input dimension. All features are flatten as a vector.\n",
    "            dim_latent (in): the number of the dimension for latent feature. Default is 2.\n",
    "            lay_den_enc (list[int]): the numbers of each dense layer. Default is [64].\n",
    "            lay_den_dec (list[int]): the numbers of each dense layer of decoder. Default is None that means reverse order of encoder.\n",
    "            act_dense (string): the activation function. Default is \"leaky_relu\".\n",
    "            dropout_dense (float): the dropout layer. Default is 0.5.\n",
    "            batch_norm (bool): determine if apply batch normalization after dense layers. Default is True and epsilon=1e-5.\n",
    "            rat_recon (float): the parameter for tuning the effects between KL loss and reconstruction loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize some setting \n",
    "        super().__init__(dim_input=dim_input, dim_latent=dim_latent,\n",
    "                         lay_den_enc=lay_den_enc, lay_den_dec=lay_den_dec, act_dense=act_dense, dropout_dense=dropout_dense,\n",
    "                         batch_norm=batch_norm)\n",
    "        self._rat_recon = rat_recon\n",
    "        \n",
    "        \n",
    "    def _encoding(self, lay_den_enc, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \n",
    "        The flow of encoding with the layers of mean and variance.\n",
    "        \"\"\"\n",
    "        dim_latent = self._dim_latent\n",
    "        x = self._inputs\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        x = self._stack_dense(x, lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        # Build the mean and variance layers\n",
    "        self._z_mean = Dense(dim_latent)(x)\n",
    "        self._z_sigma_log = Dense(dim_latent)(x) # log for linear dense\n",
    "\n",
    "        # Define the sampling function for the sampling layer.\n",
    "        # Note that the function must be in the same location with encoding for saving/loadind model.\n",
    "        def sampling(args, std_eps):\n",
    "            z_mean, z_sigma_log = args\n",
    "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], K.shape(z_mean)[1]),\n",
    "                                      mean=0., stddev=std_eps)\n",
    "            return z_mean + K.exp(z_sigma_log) * epsilon  \n",
    "        \n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Lambda(sampling, arguments={\"std_eps\":self._std_eps})([self._z_mean, self._z_sigma_log])\n",
    "        self.encoder = Model(self._inputs, z, name=\"encoder\")\n",
    "\n",
    "        \n",
    "    def _loss_vae(self, tensor_input, tensor_decode):\n",
    "        \"\"\" \"\"\"\n",
    "        z_mean = self._z_mean\n",
    "        z_sigma_log = self._z_sigma_log\n",
    "        rat_recon = self._rat_recon\n",
    "        \n",
    "        lossRecon =  binary_crossentropy(K.flatten(tensor_input), K.flatten(tensor_decode))\n",
    "#         lossRecon =  mean_squared_error(K.flatten(tensor_input), K.flatten(tensor_decode))\n",
    "        lossKL = - 0.5 * K.sum(1 + 2 * z_sigma_log - K.square(z_mean) - K.square(K.exp(z_sigma_log)), axis=-1)\n",
    "        return rat_recon * lossRecon + (1 - rat_recon) * lossKL\n",
    "        \n",
    "        \n",
    "    def fit(self,\n",
    "            x_train, x_valid,\n",
    "            num_epochs=50, size_batch=32, name_optim=\"adam\", metrics=None, verb=1,\n",
    "            path_temp_best=None, patience=3):\n",
    "        \"\"\"\n",
    "        The method is for training process. \n",
    "        The users can call this method easily just putting training and validation datasets.\n",
    "        The dimension of dataset is determined by [#instance, *dimInput].\n",
    "        For example, dimInput is flatten as a number and the dimension of dataset is [#instance, #feature]\n",
    "        If dimInput is a list to represent [width, height, channels], the dimension of dataset is [#instance, width, height, channels]\n",
    "        Args:\n",
    "            x_train (numpy ndarray): the training dataset.\n",
    "            x_valid (numpy ndarray): the validation dataset.\n",
    "            num_epochs (int): the maximal epochs for training. Default is 50.\n",
    "            size_batch (int): the batch size. Default is 32.\n",
    "            name_optim (string): the method for optimization. Default is adam.\n",
    "            metrics (list(string or keras metrics)): the usage is the same with keras metrics for compile \n",
    "            verb(int): verbose; it is applied for both of fit and callback. The setting is similar to keras.\n",
    "            path_temp_best (string): the temperory path of the best model for early-stop. Default None means without early-stop. \n",
    "            patience (int): the times of epochs to allow further trying if current loss is not better than the best. \n",
    "        Returns:\n",
    "            history (keras.callbacks.History): the learning curving for the training process\n",
    "            time_train (float): the consuming time of the training \n",
    "        \"\"\"\n",
    "        self.autoencoder.compile(optimizer=name_optim, loss=self._loss_vae, metrics=metrics)\n",
    "        \n",
    "        if path_temp_best is None:\n",
    "            callbacks = None\n",
    "        else:\n",
    "            if not os.path.exists(path_temp_best): # make sure the folder exists\n",
    "                os.makedirs(path_temp_best)\n",
    "            \n",
    "            name_temp = \"AutoEncoder\" + str(time()) # use timestamp as unique name\n",
    "            cb_es = EarlyStopping(monitor=\"val_loss\", patience=patience, verbose=verb, mode=\"auto\")\n",
    "            chkpt = path_temp_best + \"/\" + name_temp + \".hdf5\"\n",
    "            cb_cp = ModelCheckpoint(filepath=chkpt, monitor=\"val_loss\", verbose=verb, save_best_only=True, mode=\"auto\")\n",
    "            callbacks = [cb_es, cb_cp]\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        tic = time()\n",
    "        history = self.autoencoder.fit(x_train, x_train,\n",
    "                                       epochs=num_epochs,\n",
    "                                       batch_size=size_batch, shuffle=True,\n",
    "                                       callbacks=callbacks,\n",
    "                                       validation_data=(x_valid, x_valid),\n",
    "                                       verbose=verb)\n",
    "        time_train = time() - tic\n",
    "        \n",
    "        # Assure the models are resuming from the best models\n",
    "        if path_temp_best is not None:\n",
    "            self.autoencoder = keras.models.load_model(chkpt, custom_objects={\"_loss_vae\": self._loss_vae})\n",
    "            self.encoder = self.autoencoder.layers[1]\n",
    "            self.decoder = self.autoencoder.layers[2]\n",
    "        \n",
    "        return history, time_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutinal VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(VAE):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dim_input, dim_latent=2,\n",
    "                 lay_conv_enc=[8, 32], lay_conv_dec=None, size_kernel=3, strides=2, act_conv=\"leaky_relu\", padding=\"same\",\n",
    "                 lay_den_enc=[64], lay_den_dec=None, act_dense=\"leaky_relu\", dropout_dense=0.5,\n",
    "                 batch_norm=True,\n",
    "                 rat_recon=0.998):\n",
    "        \"\"\"\n",
    "        The basic properties and pipeline will be defined in the initialization.\n",
    "        The dimension of input should be a form of a picture presented by a list [width, height, channels].\n",
    "        It should be noted that lay_den_enc defines the first half(encoder) of network. \n",
    "        The decoder will be reflected structure.\n",
    "        For example, [64, 16] and plus the latent 2 means that the nodes of encoder is [64, 16, 2]. \n",
    "        Meanwhile decoder will be [2, 16, 64].\n",
    "        It is similar for lay_conv_enc but decoder is not purely symmetric for convolution layers for this version.\n",
    "        There is another parameter should noted that rat_recon=0.5 doesn't mean the effect is half.\n",
    "        Because KL loss and reconstruction loss are not the same scale.\n",
    "        Args:\n",
    "            dim_input (list[int]): the dimension of input. E.g. [32, 28, 3] means 32 by 28 RGB pixels.\n",
    "            dim_latent (in): the number of the dimension for latent feature. Default is 2.\n",
    "            lay_conv_enc (list[int]): the numbers of each convolution layer. Default is [8, 32].\n",
    "            lay_conv_dec (list[int]): the numbers of each convolution layer of decoder. Default is None that means reverse order of encoder.\n",
    "            size_kernel (int): the size of filter kernel. Default 3 means 3 by 3.\n",
    "            strides (int): the stride for convolution. Default is 2.\n",
    "            act_conv (string): the activation function of each convolution layer. Default is \"leaky_relu\".\n",
    "            padding (string): the padding method for convolution. Default is \"same\".\n",
    "            lay_den_enc (list[int]): the numbers of each dense layer. Default is [64, 2].\n",
    "            lay_den_dec (list[int]): the numbers of each dense layer of decoder. Default is None that means reverse order of encoder.\n",
    "            act_dense (string): the activation function of each dense layer. Default is \"leaky_relu\".\n",
    "            dropout_dense (float): the dropout layer. Default is 0.5.\n",
    "            batch_norm (bool): determine if apply batch normalization after dense/conv layers. Default is True and epsilon=1e-5.\n",
    "            rat_recon (float): the parameter for tuning the effects between KL loss and reconstruction loss.\n",
    "        \"\"\"        \n",
    "        # Initialize some setting \n",
    "        self._dim_input = dim_input # dim_input is (width, height, channels)\n",
    "        self._inputs = Input(shape=(dim_input)) \n",
    "        self._dim_latent = dim_latent\n",
    "        if lay_conv_dec is None:\n",
    "            lay_conv_dec = lay_conv_enc[::-1]\n",
    "        if lay_den_dec is None:\n",
    "            lay_den_dec = lay_den_enc[::-1]\n",
    "        \n",
    "        self._encoding(lay_conv_enc, size_kernel, strides, act_conv, padding,\n",
    "                       lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        self._decoding(lay_conv_dec, size_kernel, strides, act_conv, padding,\n",
    "                       lay_den_dec, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        self.autoencoder = Model(self._inputs, self.decoder(self.encoder(self._inputs)), name=\"autoencoder\")\n",
    "        self._rat_recon = rat_recon\n",
    "        \n",
    "    \n",
    "    def _stack_conv(self, x, \n",
    "                   lay_conv_enc, size_kernel, strides, padding,\n",
    "                   batch_norm, act_conv, is_trans=False):\n",
    "        \"\"\"\n",
    "        Stacking for convolutional layers whether encoder or decoder. \n",
    "        It's basic the same with the function of ConvAE.\n",
    "        \"\"\"\n",
    "        for filters in lay_conv_enc:\n",
    "            if is_trans:\n",
    "                x = Conv2DTranspose(filters=filters,\n",
    "                                    kernel_size=size_kernel,\n",
    "                                    strides=strides,\n",
    "                                    padding=padding)(x)\n",
    "            else:\n",
    "                x = Conv2D(filters=filters,\n",
    "                           kernel_size=size_kernel,\n",
    "                           strides=strides,\n",
    "                           padding=padding)(x)\n",
    "            if batch_norm :\n",
    "                x = BatchNormalization(epsilon=1e-5)(x)\n",
    "            if act_conv == \"leaky_relu\":\n",
    "                x = LeakyReLU()(x)\n",
    "            else:\n",
    "                x = Activation(act_conv)(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "    def _encoding(self,\n",
    "                  lay_conv_enc, size_kernel, strides, act_conv, padding,\n",
    "                  lay_den_enc, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \"\"\"\n",
    "        dim_latent = self._dim_latent\n",
    "        x = self._inputs\n",
    "        \n",
    "        # Stack of Conv2D layers\n",
    "        x = self._stack_conv(x, \n",
    "                            lay_conv_enc, size_kernel, strides, padding,\n",
    "                            batch_norm, act_conv)\n",
    "\n",
    "        # Shape info needed to build Decoder Model\n",
    "        self._shape_last_conv = K.int_shape(x)\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        x = Flatten()(x)\n",
    "        x = self._stack_dense(x, lay_den_enc, batch_norm, act_dense, dropout_dense)\n",
    "        \n",
    "        # Build the mean and variance layers\n",
    "        self._z_mean = Dense(dim_latent)(x)\n",
    "        self._z_sigma_log = Dense(dim_latent)(x) # log for linear dense\n",
    "\n",
    "        # Define the sampling function for the sampling layer.\n",
    "        # Note that the function must be in the same location with encoding for saving/loadind model.\n",
    "        def sampling(args, std_eps):\n",
    "            z_mean, z_sigma_log = args\n",
    "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], K.shape(z_mean)[1]),\n",
    "                                      mean=0., stddev=std_eps)\n",
    "            return z_mean + K.exp(z_sigma_log) * epsilon  \n",
    "        \n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Lambda(sampling, arguments={\"std_eps\":self._std_eps})([self._z_mean, self._z_sigma_log])\n",
    "        self.encoder = Model(self._inputs, z, name=\"encoder\")\n",
    "\n",
    "        \n",
    "    def _decoding(self,\n",
    "                  lay_conv_dec, size_kernel, strides, act_conv, padding,\n",
    "                  lay_den_dec, batch_norm, act_dense, dropout_dense):\n",
    "        \"\"\" \"\"\"\n",
    "        shape_last_conv = self._shape_last_conv\n",
    "        # Build the Decoder Model\n",
    "        input_latent = Input(shape=(self._dim_latent,), name=\"decoder_input\")\n",
    "        x = input_latent\n",
    "        \n",
    "        # Stack of Dense layers\n",
    "        x = self._stack_dense(x, lay_den_dec, batch_norm, act_dense, dropout_dense)\n",
    "        x = Dense(shape_last_conv[1] * shape_last_conv[2] * shape_last_conv[3])(x)\n",
    "        x = Reshape((shape_last_conv[1], shape_last_conv[2], shape_last_conv[3]))(x)\n",
    "\n",
    "        # Stack of Transposed Conv2D layers\n",
    "        x = self._stack_conv(x, \n",
    "                             lay_conv_dec, size_kernel, strides, padding,\n",
    "                             batch_norm, act_conv, is_trans=True)\n",
    "\n",
    "        # Build the Conv2DTranspose layer for the pixel dimension\n",
    "        x = Conv2DTranspose(filters=self._dim_input[-1],\n",
    "                            kernel_size=size_kernel,\n",
    "#                             strides=strides,\n",
    "                            padding=padding)(x)\n",
    "\n",
    "        # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "        outputs = Activation(\"sigmoid\", name=\"decoder_output\")(x)\n",
    "        self.decoder = Model(input_latent, outputs, name=\"decoder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
