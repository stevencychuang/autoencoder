{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "numSeed = 42\n",
    "random.seed(42)\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import *\n",
    "from loadFrey import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 28, 20)\n",
      "(565, 28, 20)\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest = load_frey_face_dataset()\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 560)\n",
      "(565, 560)\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest = load_frey_face_dataset()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "dimInput = np.prod(xTrain.shape[1:])\n",
    "sizeDigit = xTrain.shape[1]\n",
    "\n",
    "xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "xTest = xTest.reshape((numTest, dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the parameters and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 50\n",
    "sizeBatch = 32\n",
    "dimInter = 64\n",
    "dimEncode = 2\n",
    "stdEps = 1.0 \n",
    "ratRecon = 0.995\n",
    "nameOptim = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layEncInt = Dense(dimInter, activation='relu')\n",
    "layMean = Dense(dimEncode)\n",
    "laySigma = Dense(dimEncode)\n",
    "layDecInt = Dense(dimInter, activation='relu')\n",
    "layDecode = Dense(dimInput, activation='sigmoid')\n",
    "\n",
    "inputs = Input(shape=(dimInput,))\n",
    "interEncode = layEncInt(inputs)\n",
    "zMean = layMean(interEncode)\n",
    "zSigmaLog = laySigma(interEncode) # log for linear dense\n",
    "\n",
    "def sampling(args):\n",
    "    zMean, zSigmaLog = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(zMean)[0], dimEncode),\n",
    "                              mean=0., stddev=stdEps)\n",
    "    return zMean + K.exp(zSigmaLog) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "# z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "z = Lambda(sampling)([zMean, zSigmaLog])\n",
    "encoder = Model(inputs, z)\n",
    "\n",
    "inputZ = Input(shape=(dimEncode,))\n",
    "interDecode = layDecInt(inputZ)\n",
    "decode = layDecode(interDecode)\n",
    "decoder = Model(inputZ, decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(inputs, decoder(encoder(inputs)))\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lossVAE(zMean, zSigmaLog):\n",
    "    def loss(tensorInput, tensorDecode):\n",
    "        lossRecon =  metrics.binary_crossentropy(tensorInput, tensorDecode)\n",
    "        lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "#         lossKL = - 0.5 * K.mean(1 + zSigmaLog - K.square(zMean) - K.exp(zSigmaLog), axis=-1)\n",
    "        return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "    return loss\n",
    "\n",
    "\n",
    "vae.compile(optimizer=nameOptim, loss=lossVAE(zMean, zSigmaLog))\n",
    "tic = time()\n",
    "history = vae.fit(xTrain, xTrain,\n",
    "                epochs=numEpochs,\n",
    "                batch_size=sizeBatch,\n",
    "                shuffle=True,\n",
    "                validation_data=(xTest, xTest))\n",
    "timeTrain = time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the historical training progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"traing consumed: \" + str(timeTrain) + \" seconds\")\n",
    "plotProgress(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the encoding and decoding results of testing data, and get the mean/std of the encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encodeTest = encoder.predict(xTest)\n",
    "decodeTest = decoder.predict(encodeTest)\n",
    "meanEncTest = np.mean(encodeTest, axis=0)\n",
    "stdEncTest = np.std(encodeTest, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare original digitals with the decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCompDecode(xTest, decodeTest, sizeDigit = (28, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the scatter of the encoding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "\n",
    "plotScatterEncode(encodeTest, None, xlim, ylim, numShow=10000)\n",
    "# scoreSilh = silhouette_score(encodeTest, yTest)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the decoding results from the encoding scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "plotScatterDecode(decoder, (28,20), [-2,2], [-2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timeTrain, history.history[\"loss\"][numEpochs-1], history.history[\"val_loss\"][numEpochs-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
