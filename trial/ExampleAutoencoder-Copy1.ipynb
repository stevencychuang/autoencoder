{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import *\n",
    "from util import importNotebook\n",
    "from module.autoencoder import VAE, ConvVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "sizeDigit = xTrain.shape[1:]\n",
    "dimInput = np.prod(xTrain.shape[1:]) # dimInput is width*height\n",
    "xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "xTest = xTest.reshape((numTest, dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "\n",
    "# Set parameters\n",
    "numEpochs = 10\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [16, 2]\n",
    "layerConv = [4, 16]\n",
    "ratRecon = 1\n",
    "nameOptim = 'adam'\n",
    "pathTempBest = '../model/temp'\n",
    "pathModel = '../model/example/VAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "vae = VAE(dimInput, layerDense=layerDense, ratRecon=ratRecon)\n",
    "history, timeTrain = vae.fit(xTrain, xTest, \n",
    "                             numEpochs=numEpochs,\n",
    "                             sizeBatch=sizeBatch,\n",
    "                             nameOptim=nameOptim,\n",
    "                             pathTempBest=pathTempBest)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "autoencoder = vae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "vae.save(pathModel)\n",
    "encoder, decoder, autoencoder = VAE.load(pathModel)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(xTest)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(sizeDigit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.3562 - val_loss: 0.2574\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25742, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.2372 - val_loss: 0.2223\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25742 to 0.22232, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.2285 - val_loss: 0.2158\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22232 to 0.21585, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.2254 - val_loss: 0.2137\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21585 to 0.21370, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.2234 - val_loss: 0.2118\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21370 to 0.21177, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.2220 - val_loss: 0.2108\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21177 to 0.21076, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.2207 - val_loss: 0.2103\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21076 to 0.21027, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.2200 - val_loss: 0.2102\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21027 to 0.21024, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.2196 - val_loss: 0.2122\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21024\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.2189 - val_loss: 0.2091\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21024 to 0.20914, saving model to ../model/temp/AutoEncoder1536571363.6614892.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    40          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 4)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     592         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 16)     64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,404\n",
      "Trainable params: 13,332\n",
      "Non-trainable params: 72\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         580       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 16,457\n",
      "Trainable params: 16,385\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 13404     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         16457     \n",
      "=================================================================\n",
      "Total params: 29,861\n",
      "Trainable params: 29,717\n",
      "Non-trainable params: 144\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    40          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 4)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     592         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 16)     64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,404\n",
      "Trainable params: 13,332\n",
      "Non-trainable params: 72\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         580       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 16,457\n",
      "Trainable params: 16,385\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 13404     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         16457     \n",
      "=================================================================\n",
      "Total params: 29,861\n",
      "Trainable params: 29,717\n",
      "Non-trainable params: 144\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9237fc0390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "sizeDigit = xTrain.shape[1:]\n",
    "dimInput = [*sizeDigit, 1] # dimInput is (width, height, channels)\n",
    "xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "xTest = xTest.reshape((numTest, *dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "\n",
    "# Set parameters\n",
    "numEpochs = 10\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [16, 2]\n",
    "layerConv = [4, 16]\n",
    "ratRecon = 1\n",
    "nameOptim = 'adam'\n",
    "pathTempBest = '../model/temp'\n",
    "pathModel = '../model/example/ConVAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dimInput, layerDense=layerDense, layerConv=layerConv, ratRecon=ratRecon)\n",
    "history, timeTrain = convVAE.fit(xTrain, xTest, \n",
    "                                 numEpochs=numEpochs,\n",
    "                                 sizeBatch=sizeBatch,\n",
    "                                 pathTempBest=pathTempBest)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(pathModel)\n",
    "encoder, decoder, autoencoder = ConvVAE.load(pathModel)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(xTest)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(sizeDigit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
