{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional AutoEncoder for Cifar dataset\n",
    "# This is modified version from the reference:\n",
    "# https://raw.githubusercontent.com/shibuiwilliam/Keras_Autoencoder/master/Cifar_Conv_AutoEncoder.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "kerasBKED = os.environ[\"KERAS_BACKEND\"] \n",
    "print(kerasBKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "chlFilter = [16, 32, 64]\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "saveDir = \"./models/\"\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide x_test into validation and test\n",
    "x_val = x_test[:7000]\n",
    "x_test = x_test[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data: (7000, 32, 32, 3) \n",
      "test data: (3000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"validation data: {0} \\ntest data: {1}\".format(x_val.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3072)              12585984  \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 2048)              6293504   \n",
      "=================================================================\n",
      "Total params: 23,101,920\n",
      "Trainable params: 23,101,696\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3072)              6294528   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              12587008  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         435       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 23,137,775\n",
      "Trainable params: 23,137,545\n",
      "Non-trainable params: 230\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(32, 32, 3))\n",
    "x = input_img\n",
    "for numChl in chlFilter:\n",
    "    x = Conv2D(numChl, (3, 3), strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "#     x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dense(3072, activation='relu')(x)\n",
    "encoded = Dense(2048, name='latent_vector')(x)\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "inputLatent = Input(shape=(tuple(encoded.shape[1:].as_list())), name='decoder_input')\n",
    "\n",
    "x = Dense(3072, activation='relu')(inputLatent)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(x)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# encoded = x\n",
    "# encoder = Model(input_img, encoded)\n",
    "# inputLatent = Input(shape=(tuple(encoded.shape[1:].as_list())), name='decoder_input')\n",
    "# x = inputLatent\n",
    "\n",
    "for numChl in chlFilter[::-1]:\n",
    "    x = Conv2DTranspose(numChl, (3, 3), strides=2, padding='same')(x)\n",
    "#     x = Conv2D(numChl, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "#     x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(3, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "decoded = Activation('sigmoid')(x)\n",
    "decoder = Model(inputLatent, decoded)\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 2048)              23101920  \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 32, 32, 3)         23137775  \n",
      "=================================================================\n",
      "Total params: 46,239,695\n",
      "Trainable params: 46,239,241\n",
      "Non-trainable params: 454\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_img, decoder(encoder(input_img)))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pretrained weights\n",
    "# model.load_weights(saveDir + \"AutoEncoder_Cifar10_Deep_weights.05-0.56-0.56.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = saveDir + 'Cifar_Conv_AutoEncoder_Adapt.{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5'\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 7000 samples\n",
      "Epoch 1/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6417\n",
      "Epoch 00001: val_loss improved from inf to 0.64005, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.01-0.64-0.64.hdf5\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 0.6417 - val_loss: 0.6401\n",
      "Epoch 2/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6296\n",
      "Epoch 00002: val_loss improved from 0.64005 to 0.62700, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.02-0.63-0.63.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.6296 - val_loss: 0.6270\n",
      "Epoch 3/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6267\n",
      "Epoch 00003: val_loss improved from 0.62700 to 0.62336, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.03-0.63-0.62.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.6267 - val_loss: 0.6234\n",
      "Epoch 4/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6212\n",
      "Epoch 00004: val_loss improved from 0.62336 to 0.61974, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.04-0.62-0.62.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.6212 - val_loss: 0.6197\n",
      "Epoch 5/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6173\n",
      "Epoch 00005: val_loss improved from 0.61974 to 0.61287, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.05-0.62-0.61.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.6173 - val_loss: 0.6129\n",
      "Epoch 6/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6114\n",
      "Epoch 00006: val_loss improved from 0.61287 to 0.61003, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.06-0.61-0.61.hdf5\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.6114 - val_loss: 0.6100\n",
      "Epoch 7/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6086\n",
      "Epoch 00007: val_loss improved from 0.61003 to 0.60775, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.07-0.61-0.61.hdf5\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.6086 - val_loss: 0.6078\n",
      "Epoch 8/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6036\n",
      "Epoch 00008: val_loss improved from 0.60775 to 0.60132, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.08-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.6036 - val_loss: 0.6013\n",
      "Epoch 9/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6013\n",
      "Epoch 00009: val_loss improved from 0.60132 to 0.60094, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.09-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.6013 - val_loss: 0.6009\n",
      "Epoch 10/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6007\n",
      "Epoch 00010: val_loss improved from 0.60094 to 0.60022, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.10-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.6007 - val_loss: 0.6002\n",
      "Epoch 11/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6002\n",
      "Epoch 00011: val_loss improved from 0.60022 to 0.59962, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.11-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.6002 - val_loss: 0.5996\n",
      "Epoch 12/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5996\n",
      "Epoch 00012: val_loss improved from 0.59962 to 0.59876, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.12-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5996 - val_loss: 0.5988\n",
      "Epoch 13/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5981\n",
      "Epoch 00013: val_loss improved from 0.59876 to 0.59812, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.13-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.5981 - val_loss: 0.5981\n",
      "Epoch 14/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5973\n",
      "Epoch 00014: val_loss improved from 0.59812 to 0.59667, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.14-0.60-0.60.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5973 - val_loss: 0.5967\n",
      "Epoch 15/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5956\n",
      "Epoch 00015: val_loss improved from 0.59667 to 0.59459, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.15-0.60-0.59.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5956 - val_loss: 0.5946\n",
      "Epoch 16/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5942\n",
      "Epoch 00016: val_loss improved from 0.59459 to 0.59396, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.16-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5942 - val_loss: 0.5940\n",
      "Epoch 17/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5936\n",
      "Epoch 00017: val_loss improved from 0.59396 to 0.59346, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.17-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.5936 - val_loss: 0.5935\n",
      "Epoch 18/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5932\n",
      "Epoch 00018: val_loss improved from 0.59346 to 0.59315, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.18-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5932 - val_loss: 0.5932\n",
      "Epoch 19/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5927\n",
      "Epoch 00019: val_loss improved from 0.59315 to 0.59209, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.19-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.5926 - val_loss: 0.5921\n",
      "Epoch 20/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5916\n",
      "Epoch 00020: val_loss improved from 0.59209 to 0.59099, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.20-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5916 - val_loss: 0.5910\n",
      "Epoch 21/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5900\n",
      "Epoch 00021: val_loss improved from 0.59099 to 0.58956, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.21-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5900 - val_loss: 0.5896\n",
      "Epoch 22/100\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5886\n",
      "Epoch 00022: val_loss improved from 0.58956 to 0.58868, saving model to ./models/Cifar_Conv_AutoEncoder_Adapt.22-0.59-0.59.hdf5\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5886 - val_loss: 0.5887\n",
      "Epoch 23/100\n",
      "21984/50000 [============>.................] - ETA: 1:25 - loss: 0.5881"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, x_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, x_val),\n",
    "                    callbacks=[es_cb, cp_cb],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, x_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize original image and reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c10test = model.predict(x_test)\n",
    "c10val = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cifar10_test: {0}\\nCifar10_val: {1}\".format(np.average(c10test), np.average(c10val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# definition to show original image and reconstructed image\n",
    "def showOrigDec(orig, dec, num=10):\n",
    "    import matplotlib.pyplot as plt\n",
    "    n = num\n",
    "    plt.figure(figsize=(20, 4))\n",
    "\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(orig[i].reshape(32, 32, 3))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i +1 + n)\n",
    "        plt.imshow(dec[i].reshape(32, 32, 3))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_test, c10test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_test[100:], c10test[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_test[200:], c10test[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_val, c10val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_val[100:], c10val[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_val[200:], c10val[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the Convolutional AutoEncoder on Cifar100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load cifar100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(x_train100, y_train100), (x_test100, y_test100) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "x_train100 = x_train100.astype('float32')\n",
    "x_test100 = x_test100.astype('float32')\n",
    "x_train100 /= 255\n",
    "x_test100 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train100 shape:', x_train100.shape)\n",
    "print(x_train100.shape[0], 'train samples')\n",
    "print(x_test100.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_train100, x_train100, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test100, x_test100, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder on Cifar100 dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c100train = model.predict(x_train100)\n",
    "c100test = model.predict(x_test100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cifar100 train: {0} \\nCifar100 test: {1}\"\n",
    "      .format(np.average(c100train), np.average(c100test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_train100, c100train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_train100[100:], c100train[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_train100[200:], c100train[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_test100, c100test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_test100[100:], c100test[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigDec(x_test100[200:], c100test[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "pathWork = os.path.dirname(os.path.realpath(\"__file__\")) + \"/../illustration/\"\n",
    "sys.path.append(pathWork)\n",
    "from sklearn.metrics import silhouette_score\n",
    "from util import plotScatterDecode, plotProgress, plotCompDecode, plotScatterEncode, addNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"traing consumed: \" + str(timeTrain) + \" seconds\")\n",
    "plotProgress(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "xTest = x_test\n",
    "yTest = y_test[7000:]\n",
    "yTest = np.squeeze(yTest, axis=1)\n",
    "encodeTest = encoder.predict(xTest)\n",
    "decodeTest = decoder.predict(encodeTest)\n",
    "meanEncTest = np.mean(encodeTest, axis=0)\n",
    "stdEncTest = np.std(encodeTest, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCompDecode(xTest, decodeTest, sizeDigit = (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (meanEncTest[0] - 4*stdEncTest[0], meanEncTest[0] + 4*stdEncTest[0])\n",
    "ylim = (meanEncTest[1] - 4*stdEncTest[1], meanEncTest[1] + 4*stdEncTest[1])\n",
    "\n",
    "plotScatterEncode(encodeTest, yTest, xlim, ylim, numShow=10000)\n",
    "scoreSilh = silhouette_score(encodeTest, yTest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "plotScatterDecode(decoder, (32,32,3), xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
