{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Copyright by Steven CY Chuang.\n",
    "All rights are reserved and explaned by the author.\n",
    "The ways to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software must be agreed by the author.\n",
    "\n",
    "\n",
    "Created on July 19, 2018.\n",
    "\n",
    "This module provides the several classes of autoencoder series.\n",
    "The use could simply use these API without defining the structure by oneself.\n",
    "\n",
    "@author: steven.cy.chuang\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, Conv2DTranspose, Activation, Flatten, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "    stdEps = 1.0\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dimInput, \n",
    "                 layerDense=[64, 2], actDense='relu',\n",
    "                 ratRecon=0.998\n",
    "                ):\n",
    "        '''\n",
    "        The basic properties and pipeline will be defined in the initialization.\n",
    "        It should be noted that layerDense defines the first half(encoder) of network. \n",
    "        The decoder will be reflected structure.\n",
    "        For example, [64, 16, 2] means the nodes of decoder will be [2, 16, 64]. \n",
    "        There is another parameter should noted that ratRecon=0.5 doesn't mean the effect is half.\n",
    "        Because KL loss and reconstruction loss are not the same scale.\n",
    "        Args:\n",
    "            dimInput (int): the number of input dimension. All features are flatten as a vector.\n",
    "            layerDense (list[int]): the numbers of each dense layer. Default is [64, 2].\n",
    "            actDense (string): the activation function. Default is 'relu'.\n",
    "            ratRecon=0.998\n",
    "        '''\n",
    "        \n",
    "        # Initialize some setting \n",
    "        self.dimInput = dimInput # dimInput is width*height\n",
    "        self.inputs = Input(shape=(dimInput,)) \n",
    "        self.dimEncode = layerDense[-1]\n",
    "        self.ratRecon = ratRecon\n",
    "        \n",
    "        self.encoding(layerDense, actDense)\n",
    "        \n",
    "        self.decoding(layerDense, actDense)\n",
    "        \n",
    "        self.autoencoder = Model(self.inputs, self.decoder(self.encoder(self.inputs)), name='autoencoder')\n",
    "\n",
    "        \n",
    "    def encoding(self, layerDense, actDense):\n",
    "        dimEncode = self.dimEncode\n",
    "        x = self.inputs\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        for numFilt in layerDense[:-1]:\n",
    "            x = Dense(numFilt, activation=actDense)(x)\n",
    "        self.zMean = Dense(self.dimEncode)(x)\n",
    "        self.zSigmaLog = Dense(self.dimEncode)(x) # log for linear dense\n",
    "\n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Lambda(self.sampling)([self.zMean, self.zSigmaLog])\n",
    "        self.encoder = Model(self.inputs, z, name='encoder')\n",
    "\n",
    "        \n",
    "    def decoding(self, layerDense, actDense):\n",
    "         # Build the Decoder Model\n",
    "        inputLatent = Input(shape=(self.dimEncode,), name='decoder_input')\n",
    "        x = inputLatent\n",
    "        for numFilt in layerDense[-2::-1]:\n",
    "            x = Dense(numFilt, activation=actDense)(x)\n",
    "            \n",
    "        # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "        outputs = Dense(self.dimInput, activation='sigmoid', name='decoder_output')(x)\n",
    "        self.decoder = Model(inputLatent, outputs, name='decoder')\n",
    "        \n",
    "        \n",
    "    def sampling(self, args):\n",
    "        zMean, zSigmaLog = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(zMean)[0], self.dimEncode),\n",
    "                                  mean=0., stddev=self.stdEps)\n",
    "        return zMean + K.exp(zSigmaLog) * epsilon  \n",
    "        \n",
    "        \n",
    "    def lossVAE(self, tensorInput, tensorDecode):\n",
    "        zMean = self.zMean\n",
    "        zSigmaLog = self.zSigmaLog\n",
    "        ratRecon = self.ratRecon\n",
    "        \n",
    "        lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "        lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "        return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "    \n",
    "    \n",
    "    def train(self,\n",
    "              xTrain, xValid,\n",
    "              numEpochs=50, sizeBatch=32, nameOptim='adam',\n",
    "              tempPathBest=None, patience=3,\n",
    "             ):\n",
    "        \n",
    "        self.autoencoder.compile(optimizer=nameOptim, loss=self.lossVAE)\n",
    "\n",
    "        if tempPathBest is None:\n",
    "            callbacks = None\n",
    "        else:\n",
    "            cbEarlyStop = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "            chkpt = tempPathBest + 'Conv_AutoEncoder.{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5'\n",
    "            cbCheckPoint = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "            callbacks = [cbEarlyStop, cbCheckPoint]\n",
    "        \n",
    "        \n",
    "        # Train the autoencoder\n",
    "        tic = time()\n",
    "        history = self.autoencoder.fit(xTrain, xTrain,\n",
    "                                       epochs=numEpochs,\n",
    "                                       batch_size=sizeBatch, shuffle=True,\n",
    "                                       callbacks=callbacks,\n",
    "                                       validation_data=(xValid, xValid)\n",
    "                                      )\n",
    "        timeTrain = time() - tic\n",
    "        \n",
    "        return history, timeTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(VAE):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dimInput, \n",
    "                 layerConv=[8, 32], sizeKernel=3, strides=2, actConv='relu', padding='same',\n",
    "                 layerDense=[64, 2], actDense='relu',\n",
    "                 ratRecon=0.998):\n",
    "        '''\n",
    "        The basic properties and pipeline will be defined in the initialization.\n",
    "        It should be noted that layerDense defines the first half(encoder) of network. \n",
    "        The decoder will be reflected structure.\n",
    "        For example, [64, 16, 2] means the nodes of decoder will be [2, 16, 64].\n",
    "        It is similar for layerConv but decoder is not purely symmetric for convolution layers for this version.\n",
    "        There is another parameter should noted that ratRecon=0.5 doesn't mean the effect is half.\n",
    "        Because KL loss and reconstruction loss are not the same scale.\n",
    "        Args:\n",
    "            dimInput (int): the number of input dimension. All features are flatten as a vector.\n",
    "            layerConv (list[int]): the numbers of each convolution layer. Default is [8, 32].\n",
    "            sizeKernel (int): the size of filter kernel. Default 3 means 3 by 3.\n",
    "            strides (int): the stride for convolution. Default is 2.\n",
    "            actConv (string): the activation function of each convolution layer. Default is 'relu'.\n",
    "            padding (string): the padding method for convolution. Default is 'same'.\n",
    "            layerDense (list[int]): the numbers of each dense layer. Default is [64, 2].\n",
    "            actDense (string): the activation function of each dense layer. Default is 'relu'.\n",
    "            ratRecon=0.998\n",
    "        '''\n",
    "        \n",
    "        # Initialize some setting \n",
    "        self.dimInput = dimInput # dimInput is (width, height, channels)\n",
    "        self.inputs = Input(shape=(dimInput)) \n",
    "        self.dimEncode = layerDense[-1]\n",
    "        self.ratRecon = ratRecon\n",
    "        \n",
    "        self.encoding(layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                )\n",
    "        \n",
    "        self.decoding(layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                )\n",
    "        \n",
    "        self.autoencoder = Model(self.inputs, self.decoder(self.encoder(self.inputs)), name='autoencoder')\n",
    "        \n",
    "\n",
    "        \n",
    "    def encoding(self, \n",
    "                 layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                ):\n",
    "        dimEncode = self.dimEncode\n",
    "        x = self.inputs\n",
    "        # Stack of Conv2D layers\n",
    "        for filters in layerConv:\n",
    "            x = Conv2D(filters=filters,\n",
    "                       kernel_size=sizeKernel,\n",
    "                       strides=strides,\n",
    "                       activation=actConv,\n",
    "                       padding=padding)(x)\n",
    "\n",
    "        # Shape info needed to build Decoder Model\n",
    "        self.shape = K.int_shape(x)\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        x = Flatten()(x)\n",
    "        for numFilt in layerDense[:-1]:\n",
    "            x = Dense(numFilt, activation=actDense)(x)\n",
    "        self.zMean = Dense(dimEncode)(x)\n",
    "        self.zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Lambda(self.sampling)([self.zMean, self.zSigmaLog])\n",
    "        self.encoder = Model(self.inputs, z, name='encoder')\n",
    "\n",
    "        \n",
    "    def decoding(self,\n",
    "                 layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                ):\n",
    "        \n",
    "        shape = self.shape\n",
    "         # Build the Decoder Model\n",
    "        inputLatent = Input(shape=(self.dimEncode,), name='decoder_input')\n",
    "        x = inputLatent\n",
    "        for numFilt in layerDense[-2::-1]:\n",
    "            x = Dense(numFilt, activation=actDense)(x)\n",
    "            \n",
    "        x = Dense(shape[1] * shape[2] * shape[3])(x)\n",
    "        x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "        # Stack of Transposed Conv2D layers\n",
    "        for numFilt in layerConv[::-1]:\n",
    "            x = Conv2DTranspose(filters=numFilt,\n",
    "                                kernel_size=sizeKernel,\n",
    "                                strides=strides,\n",
    "                                activation=actConv,\n",
    "                                padding=padding)(x)\n",
    "\n",
    "        # Build the Conv2DTranspose layer for the pixel dimension\n",
    "        x = Conv2DTranspose(filters=self.dimInput[-1],\n",
    "                            kernel_size=sizeKernel,\n",
    "#                             strides=strides,\n",
    "                            padding=padding)(x)\n",
    "\n",
    "        # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "        outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "        self.decoder = Model(inputLatent, outputs, name='decoder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
