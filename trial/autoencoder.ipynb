{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, Conv2DTranspose, Activation, Flatten, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE():\n",
    "    stdEps = 1.0\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dimInput, \n",
    "                 layerConv=[8, 32], sizeKernel=3, strides=2, actConv='relu', padding='same',\n",
    "                 layerDense=[64, 2], actDense='relu',\n",
    "                 ratRecon=0.998):\n",
    "        \n",
    "        # Initialize some setting \n",
    "        self.dimInput = dimInput # dimInput is (width, height, channels)\n",
    "        self.inputs = Input(shape=(dimInput)) \n",
    "        self.dimEncode = layerDense[-1]\n",
    "        self.ratRecon = ratRecon\n",
    "        \n",
    "        self.encoding(layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                )\n",
    "        \n",
    "        self.decoding(layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                )\n",
    "        \n",
    "        self.autoencoder = Model(self.inputs, self.decoder(self.encoder(self.inputs)), name='autoencoder')\n",
    "        \n",
    "\n",
    "        \n",
    "    def encoding(self, \n",
    "                 layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                ):\n",
    "        dimEncode = self.dimEncode\n",
    "        x = self.inputs\n",
    "        # Stack of Conv2D layers\n",
    "        for filters in layerConv:\n",
    "            x = Conv2D(filters=filters,\n",
    "                       kernel_size=sizeKernel,\n",
    "                       strides=strides,\n",
    "                       activation=actConv,\n",
    "                       padding=padding)(x)\n",
    "\n",
    "        # Shape info needed to build Decoder Model\n",
    "        self.shape = K.int_shape(x)\n",
    "\n",
    "        # Stack of Dense layers\n",
    "        x = Flatten()(x)\n",
    "        for numFilt in layerDense[:-1]:\n",
    "            x = Dense(numFilt, activation=actDense)(x)\n",
    "        self.zMean = Dense(dimEncode)(x)\n",
    "        self.zSigmaLog = Dense(dimEncode)(x) # log for linear dense\n",
    "\n",
    "        # Construct the latent as the output and build the encorder pipeline\n",
    "        z = Lambda(self.sampling)([self.zMean, self.zSigmaLog])\n",
    "        self.encoder = Model(self.inputs, z, name='encoder')\n",
    "\n",
    "        \n",
    "    def decoding(self,\n",
    "                 layerConv, sizeKernel, strides, actConv, padding,\n",
    "                 layerDense, actDense,\n",
    "                ):\n",
    "        \n",
    "        shape = self.shape\n",
    "         # Build the Decoder Model\n",
    "        inputLatent = Input(shape=(self.dimEncode,), name='decoder_input')\n",
    "        x = inputLatent\n",
    "        for numFilt in layerDense[-2::-1]:\n",
    "            x = Dense(numFilt, activation=actDense)(x)\n",
    "            \n",
    "        x = Dense(shape[1] * shape[2] * shape[3])(x)\n",
    "        x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "        # Stack of Transposed Conv2D layers\n",
    "        for numFilt in layerConv[-2::-1]:\n",
    "            x = Conv2DTranspose(filters=numFilt,\n",
    "                                kernel_size=sizeKernel,\n",
    "                                strides=strides,\n",
    "                                activation=actConv,\n",
    "                                padding=padding)(x)\n",
    "\n",
    "        # Build the Conv2DTranspose layer for the pixel dimension\n",
    "        x = Conv2DTranspose(filters=self.dimInput[-1],\n",
    "                            kernel_size=sizeKernel,\n",
    "                            strides=strides,\n",
    "                            activation=actConv,\n",
    "                            padding=padding)(x)\n",
    "\n",
    "        # Reconstruct the pixels as the output and build the decorder pipeline\n",
    "        outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "        self.decoder = Model(inputLatent, outputs, name='decoder')\n",
    "        \n",
    "        \n",
    "    def sampling(self, args):\n",
    "        zMean, zSigmaLog = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(zMean)[0], self.dimEncode),\n",
    "                                  mean=0., stddev=stdEps)\n",
    "        return zMean + K.exp(zSigmaLog) * epsilon  \n",
    "        \n",
    "        \n",
    "    def lossVAE(self, args):\n",
    "        zMean, zSigmaLog = args\n",
    "        def loss(tensorInput, tensorDecode):\n",
    "            lossRecon =  metrics.binary_crossentropy(K.flatten(tensorInput), K.flatten(tensorDecode))\n",
    "            lossKL = - 0.5 * K.sum(1 + 2 * zSigmaLog - K.square(zMean) - K.square(K.exp(zSigmaLog)), axis=-1)\n",
    "    #         lossKL = - 0.5 * K.mean(1 + zSigmaLog - K.square(zMean) - K.exp(zSigmaLog), axis=-1)\n",
    "            return ratRecon * lossRecon + (1 - ratRecon) * lossKL\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def train(self,\n",
    "              xTrain, xValid,\n",
    "              numEpochs=50, sizeBatch=32, nameOptim='adam',\n",
    "              tempPathBest=None, patience=3,\n",
    "              layerConv=[8, 32], sizeKernel=3, strides=2, actConv='relu', padding='same',\n",
    "              layerDense=[64, 2], actDense='relu',\n",
    "             ):\n",
    "        \n",
    "        self.autoencoder.compile(optimizer=nameOptim, loss=self.lossVAE([self.zMean, self.zSigmaLog]))\n",
    "\n",
    "        # Train the autoencoder\n",
    "        tic = time()\n",
    "        history = self.autoencoder.fit(xTrain, xTrain,\n",
    "                        epochs=numEpochs,\n",
    "                        batch_size=sizeBatch,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(xValid, xValid))\n",
    "        timeTrain = time() - tic\n",
    "        \n",
    "        return history, timeTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 50\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [128, 32, 2]\n",
    "layerConv = [8, 32]\n",
    "stdEps = 1.0 \n",
    "ratRecon = 0.999999\n",
    "factNoise = 0\n",
    "nameOptim = 'adam'\n",
    "modelPath = '../model/temp/'\n",
    "patience = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "numClass = 10\n",
    "dimInput = [*xTrain.shape[1:], 1]\n",
    "sizeDigit = xTrain.shape[1]\n",
    "\n",
    "xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "xTest = xTest.reshape((numTest, *dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 28, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convVAE = ConvVAE(dimInput, layerDense=layerDense, layerConv=layerConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 8)    80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 32)     2336        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1568)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          200832      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            66          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 207,508\n",
      "Trainable params: 207,508\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1568)              202272    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 8)         2312      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         73        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 208,977\n",
      "Trainable params: 208,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 207508    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         208977    \n",
      "=================================================================\n",
      "Total params: 416,485\n",
      "Trainable params: 416,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convVAE.encoder.summary()\n",
    "convVAE.decoder.summary()\n",
    "convVAE.autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.6842 - val_loss: 0.6796\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.6797 - val_loss: 0.6784\n",
      "Epoch 3/50\n",
      "40192/60000 [===================>..........] - ETA: 4s - loss: 0.6787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3542adcc627d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizeBatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e410266be53e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, xTrain, xValid, numEpochs, sizeBatch, nameOptim, tempPathBest, patience, layerConv, sizeKernel, strides, actConv, padding, layerDense, actDense)\u001b[0m\n\u001b[1;32m    123\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msizeBatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                         validation_data=(xValid, xValid))\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtimeTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convVAE.train(xTrain, xTest, sizeBatch=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
