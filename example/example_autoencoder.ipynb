{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on 2018/09/01\n",
    "Revised on 2018/10/29\n",
    "\n",
    "@author: STEVEN.CY.CHUANG\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.visualization import *\n",
    "from util import import_notebook\n",
    "from module.autoencoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8)            32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 8)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8)            0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            36          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            36          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4)            0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,864\n",
      "Trainable params: 12,816\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12864     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,472\n",
      "Trainable params: 26,376\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8)            32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 8)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8)            0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            36          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            36          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4)            0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,864\n",
      "Trainable params: 12,816\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12864     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,472\n",
      "Trainable params: 26,376\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5526d8f7b8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_valid, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_valid = x_valid.astype('float32') / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_valid)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = np.prod(x_train.shape[1:]) # dim_input is width*height\n",
    "x_train = x_train.reshape((num_train, dim_input))\n",
    "x_valid = x_valid.reshape((num_test, dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "dim_latent = 4\n",
    "lay_den_enc = [16, 8]\n",
    "rat_recon = 1\n",
    "name_optim = \"adam\"\n",
    "path_temp_best = \"../model/temp/\"\n",
    "path_model = '../model/example/VAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "vae = VAE(dim_input, dim_latent, lay_den_enc=lay_den_enc, rat_recon=rat_recon)\n",
    "\n",
    "history, time_train = vae.fit(x_train, x_valid, \n",
    "                              num_epochs=num_epochs,\n",
    "                              size_batch=size_batch,\n",
    "                              path_temp_best=path_temp_best,\n",
    "                              verb=0\n",
    "                             )\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "autoencoder = vae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "vae.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_valid)\n",
    "generate = decoder.predict(np.array([[0, 0, 0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 90.7560 - val_loss: 0.8163\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81626, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 7.3586 - val_loss: 0.5954\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81626 to 0.59538, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 4.9448 - val_loss: 0.5372\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.59538 to 0.53717, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 4.1238 - val_loss: 0.5010\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.53717 to 0.50104, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 3.5622 - val_loss: 0.4678\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50104 to 0.46776, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 3.1572 - val_loss: 0.4487\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46776 to 0.44866, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 2.9413 - val_loss: 0.4430\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44866 to 0.44303, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 2.5579 - val_loss: 0.4180\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44303 to 0.41797, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 2.3565 - val_loss: 0.4079\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41797 to 0.40792, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.3307 - val_loss: 0.3932\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.40792 to 0.39325, saving model to ../model/temp/AutoEncoder1540866179.9605734.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    68          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 14, 14, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     1040        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 16)     64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 7, 7, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            6280        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8)            32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 8)            0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8)            0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    68          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 14, 14, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     1040        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 16)     64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 7, 7, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            6280        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8)            32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 8)            0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8)            0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54e649d048>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_test)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = [*size_digit, 1] # dim_input is (width, height, channels)\n",
    "x_train = x_train.reshape((num_train, *dim_input))\n",
    "x_test = x_test.reshape((num_test, *dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "size_kernel = 4\n",
    "lay_conv_enc = [4, 16]\n",
    "lay_den_enc = [8]\n",
    "rat_recon = 0.9\n",
    "name_optim = 'adam'\n",
    "path_temp_best = '../model/temp'\n",
    "path_model = '../model/example/ConvVAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dim_input, size_kernel=size_kernel, lay_conv_enc=lay_conv_enc, lay_den_enc=lay_den_enc, rat_recon=rat_recon)\n",
    "history, timeTrain = convVAE.fit(x_train, x_test, \n",
    "                                 num_epochs=num_epochs,\n",
    "                                 size_batch=size_batch,\n",
    "                                 path_temp_best=path_temp_best)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_test)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
