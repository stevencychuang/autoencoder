{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on 2018/09/01\n",
    "Revised on 2018/10/29\n",
    "\n",
    "@author: STEVEN.CY.CHUANG\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append(\"../\")\n",
    "from util.visualization import *\n",
    "from util import import_notebook\n",
    "from module.autoencoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.6733 - val_loss: 0.6485\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.5742 - val_loss: 0.4882\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.4012 - val_loss: 0.3236\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.3157 - val_loss: 0.2795\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.2909 - val_loss: 0.2661\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.2805 - val_loss: 0.2594\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.2745 - val_loss: 0.2556\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.2709 - val_loss: 0.2529\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.2680 - val_loss: 0.2510\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.2662 - val_loss: 0.2492\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,828\n",
      "Trainable params: 12,780\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12828     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,436\n",
      "Trainable params: 26,340\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,828\n",
      "Trainable params: 12,780\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12828     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,436\n",
      "Trainable params: 26,340\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f266829b588>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_valid, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_valid = x_valid.astype(\"float32\") / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_valid)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = np.prod(x_train.shape[1:]) # dim_input is width*height\n",
    "x_train = x_train.reshape((num_train, dim_input))\n",
    "x_valid = x_valid.reshape((num_test, dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "dim_latent = 4\n",
    "lay_den_enc = [16, 8]\n",
    "name_optim = \"adadelta\"\n",
    "path_model = \"../model/example/AE\"\n",
    "\n",
    "# Initialize and train\n",
    "ae = AE(dim_input, dim_latent, lay_den_enc=lay_den_enc)\n",
    "\n",
    "history, time_train = ae.fit(x_train, x_valid, \n",
    "                             num_epochs=num_epochs,\n",
    "                             size_batch=size_batch,\n",
    "                             name_optim=name_optim,\n",
    "                             verb=2)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = ae.encoder\n",
    "decoder = ae.decoder\n",
    "autoencoder = ae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "ae.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_valid)\n",
    "generate = decoder.predict(np.array([[0, 0, 0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 5334.7358 - val_loss: 1.5416\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54158, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 140.3544 - val_loss: 0.9514\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.54158 to 0.95136, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 112.0451 - val_loss: 0.7133\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.95136 to 0.71332, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 64.3408 - val_loss: 0.7141\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.71332\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 32.8883 - val_loss: 0.6826\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71332 to 0.68260, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 44.1452 - val_loss: 0.6391\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68260 to 0.63910, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 36.2452 - val_loss: 0.5969\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.63910 to 0.59691, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 30.3000 - val_loss: 0.5761\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59691 to 0.57612, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 34.2306 - val_loss: 0.5488\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.57612 to 0.54882, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 22.7460 - val_loss: 0.5296\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54882 to 0.52964, saving model to ../model/temp/AutoEncoder1540955080.066765.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    68          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     1040        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 16)     64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7, 7, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            6280        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8)            32          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8)            0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8)            0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    68          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     1040        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 16)     64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7, 7, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            6280        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8)            32          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8)            0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8)            0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            18          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f262e5597f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_test = x_test.astype(\"float32\") / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_test)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = [*size_digit, 1] # dim_input is (width, height, channels)\n",
    "x_train = x_train.reshape((num_train, *dim_input))\n",
    "x_test = x_test.reshape((num_test, *dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "size_kernel = 4\n",
    "act_conv = \"relu\"\n",
    "lay_conv_enc = [4, 16]\n",
    "act_dense = \"linear\"\n",
    "lay_den_enc = [8]\n",
    "rat_recon = 0.9\n",
    "path_temp_best = \"../model/temp\"\n",
    "path_model = \"../model/example/ConvVAE\"\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dim_input, \n",
    "                  size_kernel=size_kernel, lay_conv_enc=lay_conv_enc, act_conv=act_conv,\n",
    "                  lay_den_enc=lay_den_enc, act_dense=act_dense,\n",
    "                  rat_recon=rat_recon)\n",
    "\n",
    "history, time_train = convVAE.fit(x_train, x_test, \n",
    "                                 num_epochs=num_epochs,\n",
    "                                 size_batch=size_batch,\n",
    "                                 path_temp_best=path_temp_best)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_test)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           12560       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16)           64          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8)            32          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 8)            0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8)            0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4)            36          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            36          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,864\n",
      "Trainable params: 12,816\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12864     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,472\n",
      "Trainable params: 26,376\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           12560       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16)           64          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8)            32          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 8)            0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8)            0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4)            36          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            36          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,864\n",
      "Trainable params: 12,816\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12864     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,472\n",
      "Trainable params: 26,376\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2614b6c208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_valid, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_valid = x_valid.astype(\"float32\") / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_valid)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = np.prod(x_train.shape[1:]) # dim_input is width*height\n",
    "x_train = x_train.reshape((num_train, dim_input))\n",
    "x_valid = x_valid.reshape((num_test, dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "dim_latent = 4\n",
    "lay_den_enc = [16, 8]\n",
    "rat_recon = 1\n",
    "name_optim = \"adam\"\n",
    "path_temp_best = \"../model/temp/\"\n",
    "path_model = \"../model/example/VAE\"\n",
    "\n",
    "# Initialize and train\n",
    "vae = VAE(dim_input, dim_latent, lay_den_enc=lay_den_enc, rat_recon=rat_recon)\n",
    "history, time_train = vae.fit(x_train, x_valid, \n",
    "                              num_epochs=num_epochs,\n",
    "                              size_batch=size_batch,\n",
    "                              path_temp_best=path_temp_best,\n",
    "                              verb=0)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "autoencoder = vae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "vae.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_valid)\n",
    "generate = decoder.predict(np.array([[0, 0, 0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 5.3815 - val_loss: 0.4235\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42353, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.3862 - val_loss: 0.3360\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42353 to 0.33605, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.0259 - val_loss: 0.3064\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33605 to 0.30638, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.8599 - val_loss: 0.2923\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30638 to 0.29228, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.7450 - val_loss: 0.2816\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29228 to 0.28164, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.6530 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28164 to 0.27518, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.5960 - val_loss: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27518 to 0.27098, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.5543 - val_loss: 0.2695\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27098 to 0.26946, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.5207 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.26946 to 0.26740, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.4872 - val_loss: 0.2659\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.26740 to 0.26588, saving model to ../model/temp/AutoEncoder1540955156.9877007.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 4)    68          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 14, 14, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 16)     1040        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 16)     64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 7, 7, 16)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 784)          0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            6280        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 8)            0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           dense_18[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 4)    68          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 14, 14, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 16)     1040        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 16)     64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 7, 7, 16)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 784)          0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            6280        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 8)            0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           dense_18[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f25ac5fb828>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_test = x_test.astype(\"float32\") / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_test)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = [*size_digit, 1] # dim_input is (width, height, channels)\n",
    "x_train = x_train.reshape((num_train, *dim_input))\n",
    "x_test = x_test.reshape((num_test, *dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "size_kernel = 4\n",
    "lay_conv_enc = [4, 16]\n",
    "lay_den_enc = [8]\n",
    "rat_recon = 0.9\n",
    "name_optim = \"adam\"\n",
    "path_temp_best = \"../model/temp\"\n",
    "path_model = \"../model/example/ConvVAE\"\n",
    "patience = 2\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dim_input, size_kernel=size_kernel, lay_conv_enc=lay_conv_enc, lay_den_enc=lay_den_enc, rat_recon=rat_recon)\n",
    "history, time_train = convVAE.fit(x_train, x_test, \n",
    "                                 num_epochs=num_epochs,\n",
    "                                 size_batch=size_batch,\n",
    "                                 path_temp_best=path_temp_best,\n",
    "                                 patience=patience)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_test)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
