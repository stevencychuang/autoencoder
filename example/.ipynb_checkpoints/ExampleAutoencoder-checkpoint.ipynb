{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import *\n",
    "from util import importNotebook\n",
    "from module.autoencoder import VAE, ConvVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3219 - val_loss: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25482, saving model to ../model/temp/AutoEncoder.01-0.32-0.25.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2627 - val_loss: 0.2439\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25482 to 0.24389, saving model to ../model/temp/AutoEncoder.02-0.26-0.24.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2544 - val_loss: 0.2394\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24389 to 0.23936, saving model to ../model/temp/AutoEncoder.03-0.25-0.24.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2498 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23936 to 0.23729, saving model to ../model/temp/AutoEncoder.04-0.25-0.24.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2470 - val_loss: 0.2358\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23729 to 0.23580, saving model to ../model/temp/AutoEncoder.05-0.25-0.24.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2454 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23580 to 0.23432, saving model to ../model/temp/AutoEncoder.06-0.25-0.23.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2439 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23432 to 0.23302, saving model to ../model/temp/AutoEncoder.07-0.24-0.23.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2423 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23302 to 0.23037, saving model to ../model/temp/AutoEncoder.08-0.24-0.23.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2407 - val_loss: 0.2285\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23037 to 0.22849, saving model to ../model/temp/AutoEncoder.09-0.24-0.23.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2395 - val_loss: 0.2278\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.22849 to 0.22776, saving model to ../model/temp/AutoEncoder.10-0.24-0.23.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,628\n",
      "Trainable params: 12,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,376\n",
      "Trainable params: 13,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 12628     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13376     \n",
      "=================================================================\n",
      "Total params: 26,004\n",
      "Trainable params: 26,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,628\n",
      "Trainable params: 12,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,376\n",
      "Trainable params: 13,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 12628     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13376     \n",
      "=================================================================\n",
      "Total params: 26,004\n",
      "Trainable params: 26,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f20db7dca58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "sizeDigit = xTrain.shape[1:]\n",
    "dimInput = np.prod(xTrain.shape[1:]) # dimInput is width*height\n",
    "xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "xTest = xTest.reshape((numTest, dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "\n",
    "# Set parameters\n",
    "numEpochs = 10\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [16, 2]\n",
    "layerConv = [4, 16]\n",
    "ratRecon = 1\n",
    "nameOptim = 'adam'\n",
    "pathTempBest = '../model/temp'\n",
    "pathModel = '../model/example/VAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "vae = VAE(dimInput, layerDense=layerDense, ratRecon=ratRecon)\n",
    "history, timeTrain = vae.fit(xTrain, xTest, \n",
    "                             numEpochs=numEpochs,\n",
    "                             sizeBatch=sizeBatch,\n",
    "                             nameOptim=nameOptim,\n",
    "                             pathTempBest=pathTempBest)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "autoencoder = vae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "vae.save(pathModel)\n",
    "encoder, decoder, autoencoder = VAE.load(pathModel)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(xTest)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(sizeDigit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.3047 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23755, saving model to ../model/temp/AutoEncoder.01-0.30-0.24.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2363 - val_loss: 0.2195\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23755 to 0.21955, saving model to ../model/temp/AutoEncoder.02-0.24-0.22.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2278 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21955 to 0.21473, saving model to ../model/temp/AutoEncoder.03-0.23-0.21.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2247 - val_loss: 0.2131\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21473 to 0.21314, saving model to ../model/temp/AutoEncoder.04-0.22-0.21.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2224 - val_loss: 0.2114\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21314 to 0.21140, saving model to ../model/temp/AutoEncoder.05-0.22-0.21.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2209 - val_loss: 0.2106\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21140 to 0.21063, saving model to ../model/temp/AutoEncoder.06-0.22-0.21.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2196 - val_loss: 0.2099\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21063 to 0.20985, saving model to ../model/temp/AutoEncoder.07-0.22-0.21.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2183 - val_loss: 0.2092\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20985 to 0.20918, saving model to ../model/temp/AutoEncoder.08-0.22-0.21.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2173 - val_loss: 0.2088\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20918 to 0.20877, saving model to ../model/temp/AutoEncoder.09-0.22-0.21.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2164 - val_loss: 0.2078\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20877 to 0.20784, saving model to ../model/temp/AutoEncoder.10-0.22-0.21.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    40          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     592         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           12560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,260\n",
      "Trainable params: 13,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         580       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 16,313\n",
      "Trainable params: 16,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 13260     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         16313     \n",
      "=================================================================\n",
      "Total params: 29,573\n",
      "Trainable params: 29,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    40          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     592         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           12560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,260\n",
      "Trainable params: 13,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         580       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 16,313\n",
      "Trainable params: 16,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 13260     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         16313     \n",
      "=================================================================\n",
      "Total params: 29,573\n",
      "Trainable params: 29,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efbc11812e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "sizeDigit = xTrain.shape[1:]\n",
    "dimInput = [*xTrain.shape[1:], 1] # dimInput is (width, height, channels)\n",
    "xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "xTest = xTest.reshape((numTest, *dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "\n",
    "# Set parameters\n",
    "numEpochs = 10\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [16, 2]\n",
    "layerConv = [4, 16]\n",
    "ratRecon = 1\n",
    "nameOptim = 'adam'\n",
    "pathTempBest = '../model/temp'\n",
    "pathModel = '../model/example/ConVAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dimInput, layerDense=layerDense, layerConv=layerConv, ratRecon=ratRecon)\n",
    "history, timeTrain = convVAE.fit(xTrain, xTest, \n",
    "                                 numEpochs=numEpochs,\n",
    "                                 sizeBatch=sizeBatch,\n",
    "                                 pathTempBest=pathTempBest)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(pathModel)\n",
    "encoder, decoder, autoencoder = ConvVAE.load(pathModel)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(xTest)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(sizeDigit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
