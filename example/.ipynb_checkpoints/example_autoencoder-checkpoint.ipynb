{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on 2018/09/01\n",
    "Revised on 2018/10/29\n",
    "\n",
    "@author: STEVEN.CY.CHUANG\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.visualization import *\n",
    "from util import import_notebook\n",
    "from module.autoencoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.6141 - val_loss: 0.5521\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55210, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4032 - val_loss: 0.3619\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55210 to 0.36188, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3251 - val_loss: 0.3003\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36188 to 0.30027, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2980 - val_loss: 0.2786\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30027 to 0.27864, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2846 - val_loss: 0.2655\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27864 to 0.26555, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2766 - val_loss: 0.2570\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.26555 to 0.25702, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2718 - val_loss: 0.2513\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25702 to 0.25132, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2669 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25132 to 0.24690, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2641 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24690 to 0.24487, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2619 - val_loss: 0.2433\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.24487 to 0.24333, saving model to ../model/temp//AutoEncoder1540864421.4880202.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           12560       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16)           64          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8)            32          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 8)            0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8)            0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            36          dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            36          dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,864\n",
      "Trainable params: 12,816\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12864     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,472\n",
      "Trainable params: 26,376\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           12560       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16)           64          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8)            32          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 8)            0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8)            0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            36          dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            36          dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,864\n",
      "Trainable params: 12,816\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,608\n",
      "Trainable params: 13,560\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 12864     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13608     \n",
      "=================================================================\n",
      "Total params: 26,472\n",
      "Trainable params: 26,376\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf1c78fba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_valid, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_valid = x_valid.astype('float32') / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_valid)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = np.prod(x_train.shape[1:]) # dim_input is width*height\n",
    "x_train = x_train.reshape((num_train, dim_input))\n",
    "x_valid = x_valid.reshape((num_test, dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "dim_latent = 4\n",
    "lay_den_enc = [16, 8]\n",
    "rat_recon = 1\n",
    "name_optim = \"adam\"\n",
    "path_temp_best = \"../model/temp/\"\n",
    "path_model = '../model/example/VAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "vae = VAE(dim_input, dim_latent, lay_den_enc=lay_den_enc, rat_recon=rat_recon)\n",
    "\n",
    "history, time_train = vae.fit(x_train, x_valid, \n",
    "                              num_epochs=num_epochs,\n",
    "                              size_batch=size_batch,\n",
    "                              path_temp_best=path_temp_best,\n",
    "                              verb=0\n",
    "                             )\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "autoencoder = vae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "vae.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_valid)\n",
    "generate = decoder.predict(np.array([[0, 0, 0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 4)    68          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 14, 14, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 16)     1040        leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 16)     64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 7, 7, 16)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 784)          0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            6280        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 8)            0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           dense_19[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 4)    68          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 14, 14, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 16)     1040        leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 16)     64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 7, 7, 16)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 784)          0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            6280        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 8)            0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            18          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           dense_19[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,536\n",
      "Trainable params: 7,480\n",
      "Non-trainable params: 56\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 784)               7056      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 4)         1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         65        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,397\n",
      "Trainable params: 12,341\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 7536      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         12397     \n",
      "=================================================================\n",
      "Total params: 19,933\n",
      "Trainable params: 19,821\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf5a2cd080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "num_train = len(x_train)\n",
    "num_test = len(x_test)\n",
    "size_digit = x_train.shape[1:]\n",
    "dim_input = [*size_digit, 1] # dim_input is (width, height, channels)\n",
    "x_train = x_train.reshape((num_train, *dim_input))\n",
    "x_test = x_test.reshape((num_test, *dim_input))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Set parameters\n",
    "num_epochs = 10\n",
    "size_batch = 512\n",
    "size_kernel = 4\n",
    "lay_conv_enc = [4, 16]\n",
    "lay_den_enc = [8]\n",
    "rat_recon = 0.9\n",
    "name_optim = 'adam'\n",
    "path_temp_best = '../model/temp'\n",
    "path_model = '../model/example/ConvVAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dim_input, size_kernel=size_kernel, lay_conv_enc=lay_conv_enc, lay_den_enc=lay_den_enc, rat_recon=rat_recon)\n",
    "history, timeTrain = convVAE.fit(x_train, x_test, \n",
    "                                 num_epochs=num_epochs,\n",
    "                                 size_batch=size_batch,\n",
    "                                 path_temp_best=path_temp_best)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(path_model)\n",
    "encoder, decoder, autoencoder = load(path_model)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(x_test)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(size_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
