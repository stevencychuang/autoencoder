{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../module/autoencoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import sys  \n",
    "sys.path.append('../')\n",
    "from util.util import *\n",
    "from util import importNotebook\n",
    "from module.autoencoder import VAE, ConvVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3198 - val_loss: 0.2608\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26077, saving model to ../model/temp/AutoEncoder.01-0.32-0.26.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2659 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26077 to 0.24598, saving model to ../model/temp/AutoEncoder.02-0.27-0.25.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2553 - val_loss: 0.2398\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24598 to 0.23976, saving model to ../model/temp/AutoEncoder.03-0.26-0.24.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2505 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23976 to 0.23737, saving model to ../model/temp/AutoEncoder.04-0.25-0.24.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2477 - val_loss: 0.2354\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23737 to 0.23544, saving model to ../model/temp/AutoEncoder.05-0.25-0.24.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2457 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23544 to 0.23436, saving model to ../model/temp/AutoEncoder.06-0.25-0.23.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2443 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23436 to 0.23328, saving model to ../model/temp/AutoEncoder.07-0.24-0.23.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2427 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23328 to 0.23171, saving model to ../model/temp/AutoEncoder.08-0.24-0.23.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2411 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23171 to 0.22992, saving model to ../model/temp/AutoEncoder.09-0.24-0.23.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2397 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.22992 to 0.22814, saving model to ../model/temp/AutoEncoder.10-0.24-0.23.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,628\n",
      "Trainable params: 12,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,376\n",
      "Trainable params: 13,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 12628     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13376     \n",
      "=================================================================\n",
      "Total params: 26,004\n",
      "Trainable params: 26,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           12560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            34          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,628\n",
      "Trainable params: 12,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 784)               13328     \n",
      "=================================================================\n",
      "Total params: 13,376\n",
      "Trainable params: 13,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 12628     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               13376     \n",
      "=================================================================\n",
      "Total params: 26,004\n",
      "Trainable params: 26,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b66cd3b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "sizeDigit = xTrain.shape[1:]\n",
    "dimInput = np.prod(xTrain.shape[1:]) # dimInput is width*height\n",
    "xTrain = xTrain.reshape((numTrain, dimInput))\n",
    "xTest = xTest.reshape((numTest, dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "\n",
    "# Set parameters\n",
    "numEpochs = 10\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [16, 2]\n",
    "layerConv = [4, 16]\n",
    "ratRecon = 1\n",
    "nameOptim = 'adam'\n",
    "pathTempBest = '../model/temp'\n",
    "pathModel = '../model/example/VAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "vae = VAE(dimInput, layerDense=layerDense, ratRecon=ratRecon)\n",
    "history, timeTrain = vae.fit(xTrain, xTest, \n",
    "                             numEpochs=numEpochs,\n",
    "                             sizeBatch=sizeBatch,\n",
    "                             nameOptim=nameOptim,\n",
    "                             pathTempBest=pathTempBest)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "autoencoder = vae.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "vae.save(pathModel)\n",
    "encoder, decoder, autoencoder = VAE.load(pathModel)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(xTest)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(sizeDigit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.2968 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23689, saving model to ../model/temp/AutoEncoder.01-0.30-0.24.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2372 - val_loss: 0.2221\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23689 to 0.22205, saving model to ../model/temp/AutoEncoder.02-0.24-0.22.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2284 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22205 to 0.21570, saving model to ../model/temp/AutoEncoder.03-0.23-0.22.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2246 - val_loss: 0.2133\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21570 to 0.21333, saving model to ../model/temp/AutoEncoder.04-0.22-0.21.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2224 - val_loss: 0.2111\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21333 to 0.21107, saving model to ../model/temp/AutoEncoder.05-0.22-0.21.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2208 - val_loss: 0.2097\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21107 to 0.20970, saving model to ../model/temp/AutoEncoder.06-0.22-0.21.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2192 - val_loss: 0.2099\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20970\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2182 - val_loss: 0.2090\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20970 to 0.20903, saving model to ../model/temp/AutoEncoder.08-0.22-0.21.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2170 - val_loss: 0.2080\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20903 to 0.20805, saving model to ../model/temp/AutoEncoder.09-0.22-0.21.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2161 - val_loss: 0.2074\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20805 to 0.20744, saving model to ../model/temp/AutoEncoder.10-0.22-0.21.hdf5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    40          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     592         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           12560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,260\n",
      "Trainable params: 13,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         580       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 16,313\n",
      "Trainable params: 16,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 13260     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         16313     \n",
      "=================================================================\n",
      "Total params: 29,573\n",
      "Trainable params: 29,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 4)    40          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 16)     592         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           12560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            34          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,260\n",
      "Trainable params: 13,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 4)         580       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 16,313\n",
      "Trainable params: 16,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 13260     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         16313     \n",
      "=================================================================\n",
      "Total params: 29,573\n",
      "Trainable params: 29,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b54afe390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.astype('float32') / 255.\n",
    "xTest = xTest.astype('float32') / 255.\n",
    "numTrain = len(xTrain)\n",
    "numTest = len(xTest)\n",
    "sizeDigit = xTrain.shape[1:]\n",
    "dimInput = [*xTrain.shape[1:], 1] # dimInput is (width, height, channels)\n",
    "xTrain = xTrain.reshape((numTrain, *dimInput))\n",
    "xTest = xTest.reshape((numTest, *dimInput))\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "\n",
    "# Set parameters\n",
    "numEpochs = 10\n",
    "sizeBatch = 128\n",
    "sizeKernel = 3\n",
    "layerDense = [16, 2]\n",
    "layerConv = [4, 16]\n",
    "ratRecon = 1\n",
    "nameOptim = 'adam'\n",
    "pathTempBest = '../model/temp'\n",
    "pathModel = '../model/example/ConVAE'\n",
    "patience = 3\n",
    "\n",
    "# Initialize and train\n",
    "convVAE = ConvVAE(dimInput, layerDense=layerDense, layerConv=layerConv, ratRecon=ratRecon)\n",
    "history, timeTrain = convVAE.fit(xTrain, xTest, \n",
    "                                 numEpochs=numEpochs,\n",
    "                                 sizeBatch=sizeBatch,\n",
    "                                 pathTempBest=pathTempBest)\n",
    "\n",
    "# Get the encoder and decoder from the trained model directly\n",
    "encoder = convVAE.encoder\n",
    "decoder = convVAE.decoder\n",
    "autoencoder = convVAE.autoencoder\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Save the trained model and load from the path to resume as encoder, decoder, and autoencoder\n",
    "convVAE.save(pathModel)\n",
    "encoder, decoder, autoencoder = ConvVAE.load(pathModel)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()\n",
    "\n",
    "# Encode testing dataset and get generated reconstruction\n",
    "encode = encoder.predict(xTest)\n",
    "generate = decoder.predict(np.array([[0, 0]]))\n",
    "plt.imshow(generate.reshape(sizeDigit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
